Toggle navigation *OpenReview*.net <https://openreview.net/>

  * Login <https://openreview.net/login>

Open Peer Review. Open Publishing. Open Access. Open Discussion. Open
Recommendations. Open Directory. Open API. Open Source.
×


  International Conference on Learning Representations


      ICLR 2020


        Addis Ababa, Ethiopia Apr 30 2020
        https://iclr.cc/Conferences/2020 <https://iclr.cc/Conferences/2020>

Please see the venue website for more information.

Submission Start: Aug 01 2019 11:59PM GMT, End: Sep 25 2019 02:59PM GMT

  * Your Consoles <#your-consoles>
  * Poster Presentations <#accept-poster>
  * Spotlight Presentations <#accept-spotlight>
  * Oral Presentations <#accept-talk>
  * Withdrawn/Rejected Submissions <#reject>

Loading

  *


            Program Guided Agent
            <https://openreview.net/forum?id=BkxUvnEYDH>
            <https://openreview.net/pdf?id=BkxUvnEYDH>

    Shao-Hua Sun
    <https://openreview.net/profile?email=shaohuas%40usc.edu>, Te-Lin Wu
    <https://openreview.net/profile?email=telinwu%40usc.edu>, Joseph J.
    Lim <https://openreview.net/profile?email=limjj%40usc.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 20 Replies
    Show details <#BkxUvnEYDH-details-760>
      o *TL;DR:* We propose a modular framework that can accomplish tasks specified by programs and achieve zero-shot generalization to more complex tasks.
      o *Abstract:* Developing agents that can learn to follow natural language instructions has been an emerging research direction. While being accessible and flexible, natural language instructions can sometimes be ambiguous even to humans. To address this, we propose to utilize programs, structured in a formal language, as a precise and expressive way to specify tasks. We then devise a modular framework that learns to perform a task specified by a program – as different circumstances give rise to diverse ways to accomplish the task, our framework can perceive which circumstance it is currently under, and instruct a multitask policy accordingly to fulfill each subtask of the overall task. Experimental results on a 2D Minecraft environment not only demonstrate that the proposed framework learns to reliably accomplish program instructions and achieves zero-shot generalization to more complex instructions but also verify the efficiency of the proposed modulation mechanism for learning the multitask policy. We also conduct an analysis comparing various models which learn from programs and natural language instructions in an end-to-end fashion.
      o *Keywords:* Program Execution, Program Executor, Program Understanding, Program Guided Agent, Learning to Execute, Deep Learning
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BkxUvnEYDH&name=original_pdf>
  *


            Sparse Coding with Gated Learned ISTA
            <https://openreview.net/forum?id=BygPO2VKPH>
            <https://openreview.net/pdf?id=BygPO2VKPH>

    Kailun Wu
    <https://openreview.net/profile?email=wukl14%40mails.tsinghua.edu.cn>,
    Yiwen Guo
    <https://openreview.net/profile?email=guoyiwen.ai%40bytedance.com>,
    Ziang Li
    <https://openreview.net/profile?email=liza19%40mails.tsinghua.edu.cn>,
    Changshui Zhang
    <https://openreview.net/profile?email=zcs%40mail.tsinghua.edu.cn>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#BygPO2VKPH-details-37>
      o *TL;DR:* We propose gated mechanisms to enhance learned ISTA for sparse coding, with theoretical guarantees on the superiority of the method. 
      o *Abstract:* In this paper, we study the learned iterative shrinkage thresholding algorithm (LISTA) for solving sparse coding problems.  Following assumptions made by prior works, we first discover that the code components in its estimations may be lower than expected, i.e., require gains, and to address this problem, a gated mechanism amenable to theoretical analysis is then introduced. Specific design of the gates is inspired by convergence analyses of the mechanism and hence its effectiveness can be formally guaranteed. In addition to the gain gates, we further introduce overshoot gates for compensating insufficient step size in LISTA. Extensive empirical results confirm our theoretical findings and verify the effectiveness of our method.
      o *Keywords:* Sparse coding, deep learning, learned ISTA, convergence analysis
      o *Code:* https://github.com/wukailun/GLISTA
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BygPO2VKPH&name=original_pdf>
  *


            Graph Neural Networks Exponentially Lose Expressive Power
            for Node Classification
            <https://openreview.net/forum?id=S1ldO2EFPr>
            <https://openreview.net/pdf?id=S1ldO2EFPr>

    Kenta Oono
    <https://openreview.net/profile?email=kenta_oono%40mist.i.u-tokyo.ac.jp>,
    Taiji Suzuki
    <https://openreview.net/profile?email=taiji%40mist.i.u-tokyo.ac.jp>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 11 Replies
    Hide details <#S1ldO2EFPr-details-408>
      o *TL;DR:* We relate the asymptotic behavior of graph neural networks to the graph spectra of underlying graphs and gives principled guidelines for normalizing weights.
      o *Abstract:* Graph Neural Networks (graph NNs) are a promising deep learning approach for analyzing graph-structured data. However, it is known that they do not improve (or sometimes worsen) their predictive performance as we pile up many layers and add non-lineality. To tackle this problem, we investigate the expressive power of graph NNs via their asymptotic behaviors as the layer size tends to infinity.
              Our strategy is to generalize the forward propagation of a Graph Convolutional Network (GCN), which is a popular graph NN variant, as a specific dynamical system. In the case of a GCN, we show that when its weights satisfy the conditions determined by the spectra of the (augmented) normalized Laplacian, its output exponentially approaches the set of signals that carry information of the connected components and node degrees only for distinguishing nodes.
              Our theory enables us to relate the expressive power of GCNs with the topological information of the underlying graphs inherent in the graph spectra. To demonstrate this, we characterize the asymptotic behavior of GCNs on the Erd\H{o}s -- R\'{e}nyi graph.
              We show that when the Erd\H{o}s -- R\'{e}nyi graph is sufficiently dense and large, a broad range of GCNs on it suffers from the ``information loss" in the limit of infinite layers with high probability.
              Based on the theory, we provide a principled guideline for weight normalization of graph NNs. We experimentally confirm that the proposed weight scaling enhances the predictive performance of GCNs in real data. Code is available at https://github.com/delta2323/gnn-asymptotics.
      o *Code:* https://github.com/delta2323/gnn-asymptotics
      o *Keywords:* Graph Neural Network, Deep Learning, Expressive Power
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1ldO2EFPr&name=original_pdf>
  *


            Multi-Scale Representation Learning for Spatial Feature
            Distributions using Grid Cells
            <https://openreview.net/forum?id=rJljdh4KDH>
            <https://openreview.net/pdf?id=rJljdh4KDH>

    Gengchen Mai
    <https://openreview.net/profile?email=gengchen_mai%40geog.ucsb.edu>,
    Krzysztof Janowicz
    <https://openreview.net/profile?email=janowicz%40ucsb.edu>, Bo Yan
    <https://openreview.net/profile?email=boyan1%40linkedin.com>, Rui
    Zhu <https://openreview.net/profile?email=ruizhu%40geog.ucsb.edu>,
    Ling Cai <https://openreview.net/profile?email=lingcai%40ucsb.edu>,
    Ni Lao <https://openreview.net/profile?email=noon99%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#rJljdh4KDH-details-465>
      o *Keywords:* Grid cell, space encoding, spatially explicit model, multi-scale periodic representation, unsupervised learning
      o *TL;DR:*  We propose a representation learning model called Space2vec to encode the absolute positions and spatial relationships of places.
      o *Abstract:* Unsupervised text encoding models have recently fueled substantial progress in NLP. The key idea is to use neural networks to convert words in texts to vector space representations (embeddings) based on word positions in a sentence and their contexts, which are suitable for end-to-end training of downstream tasks. We see a strikingly similar situation in spatial analysis, which focuses on incorporating both absolute positions and spatial contexts of geographic objects such as POIs into models. A general-purpose representation model for space is valuable for a multitude of tasks. However, no such general model exists to date beyond simply applying discretization or feed-forward nets to coordinates, and little effort has been put into jointly modeling distributions with vastly different characteristics, which commonly emerges from GIS data. Meanwhile, Nobel Prize-winning Neuroscience research shows that grid cells in mammals provide a multi-scale periodic representation that functions as a metric for location encoding and is critical for recognizing places and for path-integration. Therefore, we propose a representation learning model called Space2Vec to encode the absolute positions and spatial relationships of places. We conduct experiments on two real-world geographic data for two different tasks: 1) predicting types of POIs given their positions and context, 2) image classification leveraging their geo-locations. Results show that because of its multi-scale representations, Space2Vec outperforms well-established ML approaches such as RBF kernels, multi-layer feed-forward nets, and tile embedding approaches for location modeling and image classification tasks. Detailed analysis shows that all baselines can at most well handle distribution at one scale but show poor performances in other scales. In contrast, Space2Vec ’s multi-scale representation can handle distributions at different scales.
      o *Code:* https://github.com/gengchenmai/space2vec
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJljdh4KDH&name=original_pdf>
  *


            InfoGraph: Unsupervised and Semi-supervised Graph-Level
            Representation Learning via Mutual Information Maximization
            <https://openreview.net/forum?id=r1lfF2NYvH>
            <https://openreview.net/pdf?id=r1lfF2NYvH>

    Fan-Yun Sun
    <https://openreview.net/profile?email=sunfanyun%40gmail.com>, Jordan
    Hoffman
    <https://openreview.net/profile?email=jhoffmann%40g.harvard.edu>,
    Vikas Verma
    <https://openreview.net/profile?email=vikasverma.iitm%40gmail.com>,
    Jian Tang <https://openreview.net/profile?email=jian.tang%40hec.ca>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#r1lfF2NYvH-details-752>
      o *Abstract:* This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semisupervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.
      o *Keywords:* graph-level representation learning, mutual information maximization
      o *Code:* https://github.com/fanyun-sun/InfoGraph
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=r1lfF2NYvH&name=original_pdf>
  *


            On Robustness of Neural Ordinary Differential Equations
            <https://openreview.net/forum?id=B1e9Y2NYvS>
            <https://openreview.net/pdf?id=B1e9Y2NYvS>

    Hanshu YAN
    <https://openreview.net/profile?email=hanshu.yan%40u.nus.edu>,
    Jiawei DU
    <https://openreview.net/profile?email=dujiawei%40u.nus.edu>, Vincent
    TAN <https://openreview.net/profile?email=vtan%40nus.edu.sg>, Jiashi
    FENG <https://openreview.net/profile?email=elefjia%40nus.edu.sg>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 21 Replies
    Show details <#B1e9Y2NYvS-details-247>
      o *Abstract:*  Neural ordinary differential equations (ODEs) have been attracting increasing attention in various research domains recently.  There have been some works studying optimization issues and approximation capabilities of neural ODEs, but their robustness is still yet unclear. In this work, we fill this important gap by exploring robustness properties of neural ODEs both empirically and theoretically. We first present an empirical study on the robustness of the neural ODE-based networks (ODENets) by exposing them to inputs with various types of perturbations and subsequently investigating the changes of the corresponding outputs. In contrast to conventional convolutional neural networks (CNNs), we find that the ODENets are more robust against both random Gaussian perturbations and adversarial attack examples. We then provide an insightful understanding of this phenomenon by exploiting a certain desirable property of the flow of a continuous-time ODE, namely that integral curves are non-intersecting. Our work suggests that, due to their intrinsic robustness, it is promising to use neural ODEs as a basic block for building robust deep network models. To further enhance the robustness of vanilla neural ODEs, we propose the time-invariant steady neural ODE (TisODE), which regularizes the flow on perturbed data via the time-invariant property and the imposition of a steady-state constraint. We show that the TisODE method outperforms vanilla neural ODEs and also can work in conjunction with other state-of-the-art architectural methods to build more robust deep networks.
      o *Keywords:* Neural ODE
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1e9Y2NYvS&name=original_pdf>
  *


            Defending Against Physically Realizable Attacks on Image
            Classification <https://openreview.net/forum?id=H1xscnEKDr>
            <https://openreview.net/pdf?id=H1xscnEKDr>

    Tong Wu <https://openreview.net/profile?email=tongwu%40wustl.edu>,
    Liang Tong
    <https://openreview.net/profile?email=liangtong%40wustl.edu>,
    Yevgeniy Vorobeychik
    <https://openreview.net/profile?email=yvorobeychik%40wustl.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#H1xscnEKDr-details-273>
      o *TL;DR:* Defending Against Physically Realizable Attacks on Image Classification
      o *Abstract:* We study the problem of defending deep neural network approaches for image classification from physically realizable attacks. First, we demonstrate that the two most scalable and effective methods for learning robust models, adversarial training with PGD attacks and randomized smoothing, exhibit very limited effectiveness against three of the highest profile physical attacks. Next, we propose a new abstract adversarial model, rectangular occlusion attacks, in which an adversary places a small adversarially crafted rectangle in an image, and develop two approaches for efficiently computing the resulting adversarial examples. Finally, we demonstrate that adversarial training using our new attack yields image classification models that exhibit high robustness against the physically realizable attacks we study, offering the first effective generic defense against such attacks.
      o *Keywords:* defense against physical attacks, adversarial machine learning
      o *Code:* https://github.com/tongwu2020/phattacks
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1xscnEKDr&name=original_pdf>
  *


            Estimating Gradients for Discrete Random Variables by
            Sampling without Replacement
            <https://openreview.net/forum?id=rklEj2EFvB>
            <https://openreview.net/pdf?id=rklEj2EFvB>

    Wouter Kool
    <https://openreview.net/profile?email=w.w.m.kool%40uva.nl>, Herke
    van Hoof
    <https://openreview.net/profile?email=h.c.vanhoof%40uva.nl>, Max
    Welling <https://openreview.net/profile?email=m.welling%40uva.nl>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#rklEj2EFvB-details-239>
      o *Keywords:* gradient, estimator, discrete, categorical, sampling, without replacement, reinforce, baseline, variance, gumbel, vae, structured prediction
      o *TL;DR:* We derive a low-variance, unbiased gradient estimator for expectations over discrete random variables based on sampling without replacement
      o *Abstract:* We derive an unbiased estimator for expectations over discrete random variables based on sampling without replacement, which reduces variance as it avoids duplicate samples. We show that our estimator can be derived as the Rao-Blackwellization of three different estimators. Combining our estimator with REINFORCE, we obtain a policy gradient estimator and we reduce its variance using a built-in control variate which is obtained without additional model evaluations. The resulting estimator is closely related to other gradient estimators. Experiments with a toy problem, a categorical Variational Auto-Encoder and a structured prediction problem show that our estimator is the only estimator that is consistently among the best estimators in both high and low entropy settings.
      o *Code:* https://github.com/wouterkool/estimating-gradients-without-replacement
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rklEj2EFvB&name=original_pdf>
  *


            Learning to Control PDEs with Differentiable Physics
            <https://openreview.net/forum?id=HyeSin4FPB>
            <https://openreview.net/pdf?id=HyeSin4FPB>

    Philipp Holl
    <https://openreview.net/profile?email=philipp.holl%40tum.de>, Nils
    Thuerey
    <https://openreview.net/profile?email=nils.thuerey%40tum.de>,
    Vladlen Koltun
    <https://openreview.net/profile?email=vkoltun%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#HyeSin4FPB-details-830>
      o *Keywords:* Differentiable physics, Optimal control, Deep learning
      o *TL;DR:* We train a combination of neural networks to predict optimal trajectories for complex physical systems.
      o *Abstract:* Predicting outcomes and planning interactions with the physical world are long-standing goals for machine learning. A variety of such tasks involves continuous physical systems, which can be described by partial differential equations (PDEs) with many degrees of freedom. Existing methods that aim to control the dynamics of such systems are typically limited to relatively short time frames or a small number of interaction parameters. We present a novel hierarchical predictor-corrector scheme which enables neural networks to learn to understand and control complex nonlinear physical systems over long time frames. We propose to split the problem into two distinct tasks: planning and control. To this end, we introduce a predictor network that plans optimal trajectories and a control network that infers the corresponding control parameters. Both stages are trained end-to-end using a differentiable PDE solver. We demonstrate that our method successfully develops an understanding of complex physical systems and learns to control them for tasks involving PDEs such as the incompressible Navier-Stokes equations.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HyeSin4FPB&name=original_pdf>
  *


            Intensity-Free Learning of Temporal Point Processes
            <https://openreview.net/forum?id=HygOjhEYDH>
            <https://openreview.net/pdf?id=HygOjhEYDH>

    Oleksandr Shchur
    <https://openreview.net/profile?email=shchur%40in.tum.de>, Marin
    Biloš <https://openreview.net/profile?email=bilos%40in.tum.de>,
    Stephan Günnemann
    <https://openreview.net/profile?email=guennemann%40in.tum.de>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#HygOjhEYDH-details-240>
      o *TL;DR:* Learn in temporal point processes by modeling the conditional density, not the conditional intensity.
      o *Abstract:* Temporal point processes are the dominant paradigm for modeling sequences of events happening at irregular intervals. The standard way of learning in such models is by estimating the conditional intensity function.  However, parameterizing the intensity function usually incurs several trade-offs. We show how to overcome the limitations of intensity-based approaches by directly modeling the conditional distribution of inter-event times.  We draw on the literature on normalizing flows to design models that are flexible and efficient. We additionally propose a simple mixture model that matches the flexibility of flow-based models, but also permits sampling and computing moments in closed form.  The proposed models achieve state-of-the-art performance in standard prediction tasks and are suitable for novel applications, such as learning sequence embeddings and imputing missing data.
      o *Code:* https://github.com/shchur/ifl-tpp
      o *Keywords:* Temporal point process, neural density estimation
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HygOjhEYDH&name=original_pdf>
  *


            A Signal Propagation Perspective for Pruning Neural Networks
            at Initialization
            <https://openreview.net/forum?id=HJeTo2VFwH>
            <https://openreview.net/pdf?id=HJeTo2VFwH>

    Namhoon Lee
    <https://openreview.net/profile?email=namhoon%40robots.ox.ac.uk>,
    Thalaiyasingam Ajanthan
    <https://openreview.net/profile?email=thalaiyasingam.ajanthan%40anu.edu.au>,
    Stephen Gould
    <https://openreview.net/profile?email=stephen.gould%40anu.edu.au>,
    Philip H. S. Torr
    <https://openreview.net/profile?email=phst%40robots.ox.ac.uk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#HJeTo2VFwH-details-699>
      o *TL;DR:* We formally characterize the initialization conditions for effective pruning at initialization and analyze the signal propagation properties of the resulting pruned networks which leads to a method to enhance their trainability and pruning results.
      o *Abstract:* Network pruning is a promising avenue for compressing deep neural networks. A typical approach to pruning starts by training a model and then removing redundant parameters while minimizing the impact on what is learned. Alternatively, a recent approach shows that pruning can be done at initialization prior to training, based on a saliency criterion called connection sensitivity. However, it remains unclear exactly why pruning an untrained, randomly initialized neural network is effective. In this work, by noting connection sensitivity as a form of gradient, we formally characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results. Moreover, we analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve their trainability. Our modifications to the existing pruning at initialization method lead to improved results on all tested network models for image classification tasks. Furthermore, we empirically study the effect of supervision for pruning and demonstrate that our signal propagation perspective, combined with unsupervised pruning, can be useful in various scenarios where pruning is applied to non-standard arbitrarily-designed architectures.
      o *Keywords:* neural network pruning, signal propagation perspective, sparse neural networks
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HJeTo2VFwH&name=original_pdf>
  *


            Skip Connections Matter: On the Transferability of
            Adversarial Examples Generated with ResNets
            <https://openreview.net/forum?id=BJlRs34Fvr>
            <https://openreview.net/pdf?id=BJlRs34Fvr>

    Dongxian Wu
    <https://openreview.net/profile?email=wu-dx16%40mails.tsinghua.edu.cn>,
    Yisen Wang
    <https://openreview.net/profile?email=eewangyisen%40gmail.com>,
    Shu-Tao Xia
    <https://openreview.net/profile?email=xiast%40sz.tsinghua.edu.cn>,
    James Bailey
    <https://openreview.net/profile?email=baileyj%40unimelb.edu.au>,
    Xingjun Ma
    <https://openreview.net/profile?email=xingjun.ma%40unimelb.edu.au>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#BJlRs34Fvr-details-841>
      o *TL;DR:* We identify the security weakness of skip connections in ResNet-like neural networks
      o *Abstract:* Skip connections are an essential component of current state-of-the-art deep neural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt. Despite their huge success in building deeper and more powerful DNNs, we identify a surprising \emph{security weakness} of skip connections in this paper. Use of skip connections \textit{allows easier generation of highly transferable adversarial examples}. Specifically, in ResNet-like (with skip connections) neural networks, gradients can backpropagate through either skip connections or residual modules. We find that using more gradients from the skip connections rather than the residual modules according to a decay factor, allows one to craft adversarial examples with high transferability. Our method is termed \emph{Skip Gradient Method} (SGM). We conduct comprehensive transfer attacks against state-of-the-art DNNs including ResNets, DenseNets, Inceptions, Inception-ResNet, Squeeze-and-Excitation Network (SENet) and robustly trained DNNs. We show that employing SGM on the gradient flow can greatly improve the transferability of crafted attacks in almost all cases. Furthermore, SGM can be easily combined with existing black-box attack techniques, and obtain high improvements over state-of-the-art transferability methods. Our findings not only motivate new research into the architectural vulnerability of DNNs, but also open up further challenges for the design of secure DNN architectures.
      o *Keywords:* Adversarial Example, Transferability, Skip Connection, Neural Network
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJlRs34Fvr&name=original_pdf>
  *


            White Noise Analysis of Neural Networks
            <https://openreview.net/forum?id=H1ebhnEYDH>
            <https://openreview.net/pdf?id=H1ebhnEYDH>

    Ali Borji
    <https://openreview.net/profile?email=aliborji%40gmail.com>, Sikun
    Lin <https://openreview.net/profile?email=sikun%40ucsb.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#H1ebhnEYDH-details-269>
      o *Abstract:* A white noise analysis of modern deep neural networks is presented to unveil
              their biases at the whole network level or the single neuron level. Our analysis is
              based on two popular and related methods in psychophysics and neurophysiology
              namely classification images and spike triggered analysis. These methods have
              been widely used to understand the underlying mechanisms of sensory systems
              in humans and monkeys. We leverage them to investigate the inherent biases of
              deep neural networks and to obtain a first-order approximation of their functionality.
              We emphasize on CNNs since they are currently the state of the art methods
              in computer vision and are a decent model of human visual processing. In
              addition, we study multi-layer perceptrons, logistic regression, and recurrent neural
              networks. Experiments over four classic datasets, MNIST, Fashion-MNIST,
              CIFAR-10, and ImageNet, show that the computed bias maps resemble the target
              classes and when used for classification lead to an over two-fold performance than
              the chance level. Further, we show that classification images can be used to attack
              a black-box classifier and to detect adversarial patch attacks. Finally, we utilize
              spike triggered averaging to derive the filters of CNNs and explore how the behavior
              of a network changes when neurons in different layers are modulated. Our
              effort illustrates a successful example of borrowing from neurosciences to study
              ANNs and highlights the importance of cross-fertilization and synergy across machine
              learning, deep learning, and computational neuroscience.
      o *Keywords:* Classification images, spike triggered analysis, deep learning, network visualization, adversarial attack, adversarial defense, microstimulation, computational neuroscience
      o *Code:* https://github.com/aliborji/WhiteNoiseAnalysis.git
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1ebhnEYDH&name=original_pdf>
  *


            Neural Machine Translation with Universal Visual
            Representation <https://openreview.net/forum?id=Byl8hhNYPS>
            <https://openreview.net/pdf?id=Byl8hhNYPS>

    Zhuosheng Zhang
    <https://openreview.net/profile?email=zhangzs%40sjtu.edu.cn>, Kehai
    Chen <https://openreview.net/profile?email=khchen%40nict.go.jp>, Rui
    Wang <https://openreview.net/profile?email=wangrui%40nict.go.jp>,
    Masao Utiyama
    <https://openreview.net/profile?email=mutiyama%40nict.go.jp>,
    Eiichiro Sumita
    <https://openreview.net/profile?email=eiichiro.sumita%40nict.go.jp>,
    Zuchao Li
    <https://openreview.net/profile?email=charlee%40sjtu.edu.cn>, Hai
    Zhao <https://openreview.net/profile?email=zhaohai%40cs.sjtu.edu.cn>
    25 Sep 2019 (modified: 29 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#Byl8hhNYPS-details-493>
      o *TL;DR:* This work proposed a universal visual representation for neural machine translation (NMT) using retrieved images with similar topics to source sentence,  extending image applicability in NMT.
      o *Abstract:* Though visual information has been introduced for enhancing neural machine translation (NMT), its effectiveness strongly relies on the availability of large amounts of bilingual parallel sentence pairs with manual image annotations. In this paper, we present a universal visual representation learned over the monolingual corpora with image annotations, which overcomes the lack of large-scale bilingual sentence-image pairs, thereby extending image applicability in NMT. In detail, a group of images with similar topics to the source sentence will be retrieved from a light topic-image lookup table learned over the existing sentence-image pairs, and then is encoded as image representations by a pre-trained ResNet. An attention layer with a gated weighting is to fuse the visual information and text information as input to the decoder for predicting target translations. In particular, the proposed method enables the visual information to be integrated into large-scale text-only NMT in addition to the multimodel NMT. Experiments on four widely used translation datasets, including the WMT'16 English-to-Romanian, WMT'14 English-to-German, WMT'14 English-to-French, and Multi30K, show that the proposed approach achieves significant improvements over strong baselines.
      o *Keywords:* Neural Machine Translation, Visual Representation, Multimodal Machine Translation, Language Representation
      o *Code:* https://github.com/cooelf/UVR-NMT
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Byl8hhNYPS&name=original_pdf>
  *


            Tranquil Clouds: Neural Networks for Learning Temporally
            Coherent Features in Point Clouds
            <https://openreview.net/forum?id=BJeKh3VYDH>
            <https://openreview.net/pdf?id=BJeKh3VYDH>

    Lukas Prantl
    <https://openreview.net/profile?email=lukas.prantl%40tum.de>,
    Nuttapong Chentanez
    <https://openreview.net/profile?email=nuttapong26%40gmail.com>,
    Stefan Jeschke
    <https://openreview.net/profile?email=jeschke%40stefan-jeschke.com>,
    Nils Thuerey
    <https://openreview.net/profile?email=nils.thuerey%40tum.de>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#BJeKh3VYDH-details-306>
      o *Keywords:* point clouds, spatio-temporal representations, Lagrangian data, temporal coherence, super-resolution, denoising
      o *TL;DR:* We propose a generative neural network approach for temporally coherent point clouds.
      o *Abstract:* Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJeKh3VYDH&name=original_pdf>
  *


            PC-DARTS: Partial Channel Connections for Memory-Efficient
            Architecture Search
            <https://openreview.net/forum?id=BJlS634tPr>
            <https://openreview.net/pdf?id=BJlS634tPr>

    Yuhui Xu
    <https://openreview.net/profile?email=yuhuixu%40sjtu.edu.cn>, Lingxi
    Xie <https://openreview.net/profile?email=198808xc%40gmail.com>,
    Xiaopeng Zhang
    <https://openreview.net/profile?email=zxphistory%40gmail.com>, Xin
    Chen <https://openreview.net/profile?email=1410452%40tongji.edu.cn>,
    Guo-Jun Qi
    <https://openreview.net/profile?email=guojunq%40gmail.com>, Qi Tian
    <https://openreview.net/profile?email=tian.qi1%40huawei.com>,
    Hongkai Xiong
    <https://openreview.net/profile?email=xionghongkai%40sjtu.edu.cn>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#BJlS634tPr-details-884>
      o *TL;DR:* Allowing partial channel connection in super-networks to regularize and accelerate differentiable architecture search
      o *Abstract:* Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads in jointly training a super-net and searching for an optimal architecture. In this paper, we present a novel approach, namely  Partially-Connected DARTS, by sampling a small part of super-net to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance. In particular, we perform operation search in a subset of channels while bypassing the held out part in a shortcut. This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels. We solve it by introducing  edge normalization, which adds a new set of edge-level hyper-parameters to reduce uncertainty in search. Thanks to the reduced memory cost, PC-DARTS can be trained with a larger batch size and, consequently, enjoy both faster speed and higher training stability. Experiment results demonstrate the effectiveness of the proposed method. Specifically, we achieve an error rate of 2.57% on CIFAR10 within merely 0.1 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) within 3.8 GPU-days for search. Our code has been made available at https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0.
      o *Code:* https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0
      o *Keywords:* Neural Architecture Search, DARTS, Regularization, Normalization
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJlS634tPr&name=original_pdf>
  *


            Online and stochastic optimization beyond Lipschitz
            continuity: A Riemannian approach
            <https://openreview.net/forum?id=rkxZyaNtwB>
            <https://openreview.net/pdf?id=rkxZyaNtwB>

    Kimon Antonakopoulos
    <https://openreview.net/profile?email=kimon.antonakopoulos%40inria.fr>,
    E. Veronica Belmega
    <https://openreview.net/profile?email=veronica.belmega%40ensea.fr>,
    Panayotis Mertikopoulos
    <https://openreview.net/profile?email=panayotis.mertikopoulos%40imag.fr>

    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#rkxZyaNtwB-details-315>
      o *Keywords:* Online optimization, stochastic optimization, Poisson inverse problems
      o *TL;DR:* We introduce a novel version of Lipschitz objective continuity that allows stochastic mirror descent methodologies to achieve optimal convergence rates in problems with singularities.
      o *Abstract:* Motivated by applications to machine learning and imaging science, we study a class of online and stochastic optimization problems with loss functions that are not Lipschitz continuous; in particular, the loss functions encountered by the optimizer could exhibit gradient singularities or be singular themselves. Drawing on tools and techniques from Riemannian geometry, we examine a Riemann–Lipschitz (RL) continuity condition which is tailored to the singularity landscape of the problem’s loss functions. In this way, we are able to tackle cases beyond the Lipschitz framework provided by a global norm, and we derive optimal regret bounds and last iterate convergence results through the use of regularized learning methods (such as online mirror descent). These results are subsequently validated in a class of stochastic Poisson inverse problems that arise in imaging science.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rkxZyaNtwB&name=original_pdf>
  *


            Enhancing Adversarial Defense by k-Winners-Take-All
            <https://openreview.net/forum?id=Skgvy64tvr>
            <https://openreview.net/pdf?id=Skgvy64tvr>

    Chang Xiao
    <https://openreview.net/profile?email=chang%40cs.columbia.edu>,
    Peilin Zhong
    <https://openreview.net/profile?email=pz2225%40columbia.edu>,
    Changxi Zheng
    <https://openreview.net/profile?email=cxz%40cs.columbia.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#Skgvy64tvr-details-756>
      o *Keywords:* adversarial defense, activation function, winner takes all
      o *TL;DR:* We propose a simple change to existing neural network structures for better defending against gradient-based adversarial attacks, using the k-winners-take-all activation function.
      o *Abstract:* We propose a simple change to existing neural network structures for better defending against gradient-based adversarial attacks. Instead of using popular activation functions (such as ReLU), we advocate the use of k-Winners-Take-All (k-WTA) activation, a C0 discontinuous function that purposely invalidates the neural network model’s gradient at densely distributed input data points. The proposed k-WTA activation can be readily used in nearly all existing networks and training methods with no significant overhead. Our proposal is theoretically rationalized. We analyze why the discontinuities in k-WTA networks can largely prevent gradient-based search of adversarial examples and why they at the same time remain innocuous to the network training. This understanding is also empirically backed. We test k-WTA activation on various network structures optimized by a training method, be it adversarial training or not. In all cases, the robustness of k-WTA networks outperforms that of traditional networks under white-box attacks.
      o *Code:* https://github.com/a554b554/kWTA-Activation
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Skgvy64tvr&name=original_pdf>
  *


            Encoding word order in complex embeddings
            <https://openreview.net/forum?id=Hke-WTVtwr>
            <https://openreview.net/pdf?id=Hke-WTVtwr>

    Benyou Wang
    <https://openreview.net/profile?email=wang%40dei.unipd.it>, Donghao
    Zhao <https://openreview.net/profile?email=zhaodh%40tju.edu.cn>,
    Christina Lioma
    <https://openreview.net/profile?email=chrh%40di.ku.dk>, Qiuchi Li
    <https://openreview.net/profile?email=qiuchili%40dei.unipd.it>, Peng
    Zhang <https://openreview.net/profile?email=pzhang%40tju.edu.cn>,
    Jakob Grue Simonsen
    <https://openreview.net/profile?email=simonsen%40di.ku.dk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 14 Replies
    Show details <#Hke-WTVtwr-details-225>
      o *Abstract:* Sequential word order is important when processing text. Currently, neural networks (NNs) address this by modeling word position using position embeddings. The problem is that position embeddings capture the position of individual words, but not the ordered relationship (e.g., adjacency or precedence) between individual word positions. We present a novel and principled solution for modeling both the global absolute positions of words and their order relationships. Our solution generalizes word embeddings, previously defined as independent vectors, to continuous word functions over a variable (position). The benefit of continuous functions over variable positions is that word representations shift smoothly with increasing positions. Hence, word representations in different positions can correlate with each other in a continuous function. The general solution of these functions can be extended to complex-valued variants. We extend CNN, RNN and Transformer NNs to complex-valued versions to incorporate our complex embedding (we make all code available). Experiments on text classification, machine translation and language modeling show gains over both classical word embeddings and position-enriched word embeddings. To our knowledge, this is the first work in NLP to link imaginary numbers in complex-valued representations to concrete meanings (i.e., word order).
      o *Code:* https://github.com/iclr-complex-order/complex-order
      o *Keywords:* word embedding, complex-valued neural network, position embedding
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Hke-WTVtwr&name=original_pdf>
  *


            DDSP: Differentiable Digital Signal Processing
            <https://openreview.net/forum?id=B1x1ma4tDr>
            <https://openreview.net/pdf?id=B1x1ma4tDr>

    Jesse Engel
    <https://openreview.net/profile?email=jesseengel%40google.com>,
    Lamtharn (Hanoi) Hantrakul
    <https://openreview.net/profile?email=hanoih%40google.com>, Chenjie
    Gu <https://openreview.net/profile?email=gcj%40google.com>, Adam
    Roberts <https://openreview.net/profile?email=adarob%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 15 Replies
    Show details <#B1x1ma4tDr-details-295>
      o *TL;DR:* Better audio synthesis by combining interpretable DSP with end-to-end learning.
      o *Abstract:* Most generative models of audio directly generate samples in one of two domains: time or frequency. While sufficient to express any signal, these representations are inefficient, as they do not utilize existing knowledge of how sound is generated and perceived. A third approach (vocoders/synthesizers) successfully incorporates strong domain knowledge of signal processing and perception, but has been less actively researched due to limited expressivity and difficulty integrating with modern auto-differentiation-based machine learning methods. In this paper, we introduce the Differentiable Digital Signal Processing (DDSP) library, which enables direct integration of classic signal processing elements with deep learning methods. Focusing on audio synthesis, we achieve high-fidelity generation without the need for large autoregressive models or adversarial losses, demonstrating that DDSP enables utilizing strong inductive biases without losing the expressive power of neural networks. Further, we show that combining interpretable modules permits manipulation of each separate model component, with applications such as independent control of pitch and loudness, realistic extrapolation to pitches not seen during training, blind dereverberation of room acoustics, transfer of extracted room acoustics to new environments, and transformation of timbre between disparate sources. In short, DDSP enables an interpretable and modular approach to generative modeling, without sacrificing the benefits of deep learning. The library will is available at https://github.com/magenta/ddsp and we encourage further contributions from the community and domain experts.
              
      o *Keywords:* dsp, audio, music, nsynth, wavenet, wavernn, vocoder, synthesizer, sound, signal, processing, tensorflow, autoencoder, disentanglement
      o *Code:* https://github.com/magenta/ddsp
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1x1ma4tDr&name=original_pdf>
  *


            Cross-Domain Few-Shot Classification via Learned
            Feature-Wise Transformation
            <https://openreview.net/forum?id=SJl5Np4tPr>
            <https://openreview.net/pdf?id=SJl5Np4tPr>

    Hung-Yu Tseng
    <https://openreview.net/profile?email=htseng6%40ucmerced.edu>,
    Hsin-Ying Lee
    <https://openreview.net/profile?email=hlee246%40ucmerced.edu>,
    Jia-Bin Huang
    <https://openreview.net/profile?email=jbhuang%40vt.edu>, Ming-Hsuan
    Yang <https://openreview.net/profile?email=mhyang%40ucmerced.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#SJl5Np4tPr-details-306>
      o *Abstract:* Few-shot classification aims to recognize novel categories with only few labeled images in each class. Existing metric-based few-shot classification algorithms predict categories by comparing the feature embeddings of query images with those from a few labeled images (support examples) using a learned metric function. While promising performance has been demonstrated, these methods often fail to generalize to unseen domains due to large discrepancy of the feature distribution across domains. In this work, we address the problem of few-shot classification under domain shifts for metric-based methods. Our core idea is to use feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. To capture variations of the feature distributions under different domains, we further apply a learning-to-learn approach to search for the hyper-parameters of the feature-wise transformation layers. We conduct extensive experiments and ablation studies under the domain generalization setting using five few-shot classification datasets: mini-ImageNet, CUB, Cars, Places, and Plantae. Experimental results demonstrate that the proposed feature-wise transformation layer is applicable to various metric-based models, and provides consistent improvements on the few-shot classification performance under domain shift.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SJl5Np4tPr&name=original_pdf>
  *


            Ridge Regression: Structure, Cross-Validation, and Sketching
            <https://openreview.net/forum?id=HklRwaEKwB>
            <https://openreview.net/pdf?id=HklRwaEKwB>

    Sifan Liu
    <https://openreview.net/profile?email=sfliu%40stanford.edu>, Edgar
    Dobriban
    <https://openreview.net/profile?email=dobribanedgar%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 5 Replies
    Show details <#HklRwaEKwB-details-581>
      o *Keywords:* ridge regression, sketching, random matrix theory, cross-validation, high-dimensional asymptotics
      o *TL;DR:* We study the structure of ridge regression in a high-dimensional asymptotic framework, and get insights about cross-validation and sketching.
      o *Abstract:* We study the following three fundamental problems about ridge regression: (1) what is the structure of the estimator? (2) how to correctly use cross-validation to choose the regularization parameter? and (3) how to accelerate computation without losing too much accuracy? We consider the three problems in a unified large-data linear model. We give a precise representation of ridge regression as a covariance matrix-dependent linear combination of the true parameter and the noise. 
              We study the bias of $K$-fold cross-validation for choosing the regularization parameter, and propose a simple bias-correction. We analyze the accuracy of primal and dual sketching for ridge regression, showing they are surprisingly accurate. Our results are illustrated by simulations and by analyzing empirical data.
      o *Code:* https://github.com/liusf15/RidgeRegression
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HklRwaEKwB&name=original_pdf>
  *


            Finite Depth and Width Corrections to the Neural Tangent
            Kernel <https://openreview.net/forum?id=SJgndT4KwB>
            <https://openreview.net/pdf?id=SJgndT4KwB>

    Boris Hanin
    <https://openreview.net/profile?email=bhanin%40math.tamu.edu>, Mihai
    Nica <https://openreview.net/profile?email=mnica%40math.utoronto.ca>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#SJgndT4KwB-details-409>
      o *Keywords:* Neural Tangent Kernel, Finite Width Corrections, Random ReLU Net, Wide Networks, Deep Networks
      o *TL;DR:* The neural tangent kernel in a randomly initialized ReLU net is non-trivial fluctuations as long as the depth and width are comparable. 
      o *Abstract:* We prove the precise scaling, at finite depth and width, for the mean and variance of the neural tangent kernel (NTK) in a randomly initialized ReLU network. The standard deviation is exponential in the ratio of network depth to width. Thus, even in the limit of infinite overparameterization, the NTK is not deterministic if depth and width simultaneously tend to infinity. Moreover, we prove that for such deep and wide networks, the NTK has a non-trivial evolution during training by showing that the mean of its first SGD update is also exponential in the ratio of network depth to width. This is sharp contrast to the regime where depth is fixed and network width is very large. Our results suggest that, unlike relatively shallow and wide networks, deep and wide ReLU networks are capable of learning data-dependent features even in the so-called lazy training regime. 
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SJgndT4KwB&name=original_pdf>
  *


            Meta-Learning without Memorization
            <https://openreview.net/forum?id=BklEFpEYwS>
            <https://openreview.net/pdf?id=BklEFpEYwS>

    Mingzhang Yin
    <https://openreview.net/profile?email=mzyin%40utexas.edu>, George
    Tucker <https://openreview.net/profile?email=gjt%40google.com>,
    Mingyuan Zhou
    <https://openreview.net/profile?email=mingyuan.zhou%40mccombs.utexas.edu>,
    Sergey Levine
    <https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu>,
    Chelsea Finn
    <https://openreview.net/profile?email=cbfinn%40cs.stanford.edu>
    25 Sep 2019 (modified: 27 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#BklEFpEYwS-details-619>
      o *Keywords:* meta-learning, memorization, regularization, overfitting, mutually-exclusive
      o *TL;DR:* We identify and formalize the memorization problem in meta-learning and solve this problem with novel meta-regularization method, which greatly expand the domain that meta-learning can be  applicable to and effective on.
      o *Abstract:* The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes.  This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings. 
      o *Code:* https://github.com/google-research/google-research/tree/master/meta_learning_without_memorization
      o *Poster:*   pdf <https://openreview.net/attachment?id=BklEFpEYwS&name=poster>
      o *Full Presentation Video:* https://slideslive.com/38922670/invited-talk-the-big-problem-with-metalearning-and-how-bayesians-can-fix-it
      o *Slides:* https://mingzhang-yin.github.io/assets/pdfs/iclr2020_slides.pdf
      o *Spotlight Video:* https://www.youtube.com/watch?v=emUvd3WqHMs&feature=youtu.be
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BklEFpEYwS&name=original_pdf>
  *


            Influence-Based Multi-Agent Exploration
            <https://openreview.net/forum?id=BJgy96EYvr>
            <https://openreview.net/pdf?id=BJgy96EYvr>

    Tonghan Wang*
    <https://openreview.net/profile?email=tonghanwang1996%40gmail.com>,
    Jianhao Wang*
    <https://openreview.net/profile?email=1040594377%40qq.com>, Yi Wu
    <https://openreview.net/profile?email=jxwuyi%40openai.com>, Chongjie
    Zhang <https://openreview.net/profile?email=chongjie%40tsinghua.edu.cn>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#BJgy96EYvr-details-88>
      o *Keywords:* Multi-agent reinforcement learning, Exploration
      o *Abstract:* Intrinsically motivated reinforcement learning aims to address the exploration challenge for sparse-reward tasks. However, the study of exploration methods in transition-dependent multi-agent settings is largely absent from the literature. We aim to take a step towards solving this problem. We present two exploration methods: exploration via information-theoretic influence (EITI) and exploration via decision-theoretic influence (EDTI), by exploiting the role of interaction in coordinated behaviors of agents. EITI uses mutual information to capture the interdependence between the transition dynamics of agents. EDTI uses a novel intrinsic reward, called Value of Interaction (VoI), to characterize and quantify the influence of one agent's behavior on expected returns of other agents. By optimizing EITI or EDTI objective as a regularizer, agents are encouraged to coordinate their exploration and learn policies to optimize the team performance. We show how to optimize these regularizers so that they can be easily integrated with policy gradient reinforcement learning. The resulting update rule draws a connection between coordinated exploration and intrinsic reward distribution. Finally, we empirically demonstrate the significant strength of our methods in a variety of multi-agent scenarios.
      o *Code:* https://github.com/TonghanWang/EITI-EDTI
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJgy96EYvr&name=original_pdf>
  *


            HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX
            BUGS IN PROGRAMS
            <https://openreview.net/forum?id=SJeqs6EFvB>
            <https://openreview.net/pdf?id=SJeqs6EFvB>

    Elizabeth Dinella
    <https://openreview.net/profile?email=edinella%40seas.upenn.edu>,
    Hanjun Dai
    <https://openreview.net/profile?email=hadai%40google.com>, Ziyang Li
    <https://openreview.net/profile?email=liby99%40seas.upenn.edu>,
    Mayur Naik
    <https://openreview.net/profile?email=mhnaik%40cis.upenn.edu>, Le
    Song <https://openreview.net/profile?email=lsong%40cc.gatech.edu>,
    Ke Wang <https://openreview.net/profile?email=kewang%40visa.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#SJeqs6EFvB-details-378>
      o *TL;DR:* An learning-based approach for detecting and fixing bugs in Javascript
      o *Abstract:* We present a learning-based approach to detect and fix a broad range of bugs in Javascript programs. We frame the problem in terms of learning a sequence of graph transformations: given a buggy program modeled by a graph structure, our model makes a sequence of predictions including the position of bug nodes and corresponding graph edits to produce a fix. Unlike previous works that use deep neural networks, our approach targets bugs that are more complex and semantic in nature (i.e.~bugs that require adding or deleting statements to fix). We have realized our approach in a tool called HOPPITY. By training on 290,715 Javascript code change commits on Github, HOPPITY correctly detects and fixes bugs in 9,490 out of 36,361 programs in an end-to-end fashion. Given the bug location and type of the fix, HOPPITY also outperforms the baseline approach by a wide margin.
      o *Keywords:* Bug Detection, Program Repair, Graph Neural Network, Graph Transformation
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SJeqs6EFvB&name=original_pdf>
  *


            Sliced Cramer Synaptic Consolidation for Preserving Deeply
            Learned Representations
            <https://openreview.net/forum?id=BJge3TNKwH>
            <https://openreview.net/pdf?id=BJge3TNKwH>

    Soheil Kolouri
    <https://openreview.net/profile?email=skolouri%40hrl.com>, Nicholas
    A. Ketz <https://openreview.net/profile?email=naketz%40hrl.com>,
    Andrea Soltoggio
    <https://openreview.net/profile?email=a.soltoggio%40lboro.ac.uk>,
    Praveen K. Pilly
    <https://openreview.net/profile?email=pkpilly%40hrl.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 5 Replies
    Show details <#BJge3TNKwH-details-908>
      o *Keywords:* selective plasticity, catastrophic forgetting, intransigence
      o *TL;DR:* "A novel framework for overcoming catastrophic forgetting by preserving the distribution of the network's output at an arbitrary layer."
      o *Abstract:* Deep neural networks suffer from the inability to preserve the learned data representation (i.e., catastrophic forgetting) in domains where the input data distribution is non-stationary, and it changes during training.  Various selective synaptic plasticity approaches have been recently proposed to preserve network parameters, which are crucial for previously learned tasks while learning new tasks. We explore such selective synaptic plasticity approaches through a unifying lens of memory replay and show the close relationship between methods like Elastic Weight Consolidation (EWC) and Memory-Aware-Synapses (MAS).  We then propose a fundamentally different class of preservation methods that aim at preserving the distribution of internal neural representations for previous tasks while learning a new one. We propose the sliced Cram\'{e}r distance as a suitable choice for such preservation and evaluate our Sliced Cramer Preservation (SCP) algorithm through extensive empirical investigations on various network architectures in both supervised and unsupervised learning settings. We show that SCP consistently utilizes the learning capacity of the network better than online-EWC and MAS methods on various incremental learning tasks.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJge3TNKwH&name=original_pdf>
  *


            How much Position Information Do Convolutional Neural
            Networks Encode?
            <https://openreview.net/forum?id=rJeB36NKvB>
            <https://openreview.net/pdf?id=rJeB36NKvB>

    Md Amirul Islam*
    <https://openreview.net/profile?email=amirul%40scs.ryerson.ca>, Sen
    Jia* <https://openreview.net/profile?email=sen.jia%40ryerson.ca>,
    Neil D. B. Bruce
    <https://openreview.net/profile?email=bruce%40ryerson.ca>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 15 Replies
    Show details <#rJeB36NKvB-details-337>
      o *Keywords:* network understanding, absolute position information
      o *TL;DR:* Our work shows positional information has been implicitly encoded in a network. This information is important for detecting position-dependent features, e.g. semantic and saliency.
      o *Abstract:* In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJeB36NKvB&name=original_pdf>
  *


            Hamiltonian Generative Networks
            <https://openreview.net/forum?id=HJenn6VFvB>
            <https://openreview.net/pdf?id=HJenn6VFvB>

    Peter Toth
    <https://openreview.net/profile?email=petertoth%40google.com>,
    Danilo J. Rezende
    <https://openreview.net/profile?email=danilor%40google.com>, Andrew
    Jaegle
    <https://openreview.net/profile?email=drewjaegle%40google.com>,
    Sébastien Racanière
    <https://openreview.net/profile?email=sracaniere%40google.com>,
    Aleksandar Botev
    <https://openreview.net/profile?email=botev%40google.com>, Irina
    Higgins <https://openreview.net/profile?email=irinah%40google.com>
    25 Sep 2019 (modified: 23 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#HJenn6VFvB-details-731>
      o *TL;DR:* We introduce a class of generative models that reliably learn Hamiltonian dynamics from high-dimensional observations. The learnt Hamiltonian can be applied to sequence modeling or as a normalising flow.
      o *Abstract:* The Hamiltonian formalism plays a central role in classical and quantum physics. Hamiltonians are the main tool for modelling the continuous time evolution of systems with conserved quantities, and they come equipped with many useful properties, like time reversibility and smooth interpolation in time. These properties are important for many machine learning problems - from sequence prediction to reinforcement learning and density modelling - but are not typically provided out of the box by standard tools such as recurrent neural networks. In this paper, we introduce the Hamiltonian Generative Network (HGN), the first approach capable of consistently learning Hamiltonian dynamics from high-dimensional observations (such as images) without restrictive domain assumptions. Once trained, we can use HGN to sample new trajectories, perform rollouts both forward and backward in time, and even speed up or slow down the learned dynamics. We demonstrate how a simple modification of the network architecture turns HGN into a powerful normalising flow model, called Neural Hamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive densities. Hence, we hope that our work serves as a first practical demonstration of the value that the Hamiltonian formalism can bring to machine learning. More results and video evaluations are available at: http://tiny.cc/hgn
      o *Keywords:* Hamiltonian dynamics, normalising flows, generative model, physics
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HJenn6VFvB&name=original_pdf>
  *


            CoPhy: Counterfactual Learning of Physical Dynamics
            <https://openreview.net/forum?id=SkeyppEFvS>
            <https://openreview.net/pdf?id=SkeyppEFvS>

    Fabien Baradel
    <https://openreview.net/profile?email=fabien.baradel%40insa-lyon.fr>, Natalia
    Neverova <https://openreview.net/profile?email=nneverova%40fb.com>,
    Julien Mille
    <https://openreview.net/profile?email=julien.mille%40insa-cvl.fr>,
    Greg Mori <https://openreview.net/profile?email=mori%40cs.sfu.ca>,
    Christian Wolf
    <https://openreview.net/profile?email=christian.wolf%40insa-lyon.fr>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#SkeyppEFvS-details-277>
      o *Abstract:* Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.
      o *Keywords:* intuitive physics, visual reasoning
      o *Code:* https://github.com/fabienbaradel/cophy
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SkeyppEFvS&name=original_pdf>
  *


            Estimating counterfactual treatment outcomes over time
            through adversarially balanced representations
            <https://openreview.net/forum?id=BJg866NFvB>
            <https://openreview.net/pdf?id=BJg866NFvB>

    Ioana Bica
    <https://openreview.net/profile?email=ioana.bica%40eng.ox.ac.uk>,
    Ahmed M Alaa
    <https://openreview.net/profile?email=a7med3laa%40hotmail.com>,
    James Jordon
    <https://openreview.net/profile?email=james.jordon%40wolfson.ox.ac.uk>,
    Mihaela van der Schaar
    <https://openreview.net/profile?email=mschaar%40turing.ac.uk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#BJg866NFvB-details-292>
      o *Keywords:* treatment effects over time, causal inference, counterfactual estimation
      o *Abstract:* Identifying when to give treatments to patients and how to select among multiple treatments over time are important medical problems with a few existing solutions. In this paper, we introduce the Counterfactual Recurrent Network (CRN), a novel sequence-to-sequence model that leverages the increasingly available patient observational data to estimate treatment effects over time and answer such medical questions. To handle the bias from time-varying confounders, covariates affecting the treatment assignment policy in the observational data, CRN uses domain adversarial training to build balancing representations of the patient history. At each timestep, CRN constructs a treatment invariant representation which removes the association between patient history and treatment assignments and thus can be reliably used for making counterfactual predictions. On a simulated model of tumour growth, with varying degree of time-dependent confounding, we show how our model achieves lower error in estimating counterfactuals and in choosing the correct treatment and timing of treatment than current state-of-the-art methods.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJg866NFvB&name=original_pdf>
  *


            Gradientless Descent: High-Dimensional Zeroth-Order
            Optimization <https://openreview.net/forum?id=Skep6TVYDB>
            <https://openreview.net/pdf?id=Skep6TVYDB>

    Daniel Golovin
    <https://openreview.net/profile?email=dgg%40google.com>, John Karro
    <https://openreview.net/profile?email=karro%40google.com>, Greg
    Kochanski <https://openreview.net/profile?email=gpk%40google.com>,
    Chansoo Lee
    <https://openreview.net/profile?email=chansoo%40google.com>, Xingyou
    Song
    <https://openreview.net/profile?email=xingyousong%40google.com>,
    Qiuyi Zhang <https://openreview.net/profile?email=qiuyiz%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#Skep6TVYDB-details-264>
      o *Keywords:* Zeroth Order Optimization
      o *TL;DR:* Gradientless Descent is a provably efficient gradient-free algorithm that is monotone-invariant and fast for high-dimensional zero-th order optimization.
      o *Abstract:* Zeroth-order optimization is the process of minimizing an objective $f(x)$, given oracle access to evaluations at adaptively chosen inputs $x$. In this paper, we present two simple yet powerful GradientLess Descent (GLD) algorithms that do not rely on an underlying gradient estimate and are numerically stable. We analyze our algorithm from a novel geometric perspective and we show that for {\it any monotone transform} of a smooth and strongly convex objective with latent dimension $k \ge n$, we present a novel analysis that shows convergence within an $\epsilon$-ball of the optimum in $O(kQ\log(n)\log(R/\epsilon))$ evaluations, where the input dimension is $n$, $R$ is the diameter of the input space and $Q$ is the condition number. Our rates are the first of its kind to be both 1) poly-logarithmically dependent on dimensionality and 2) invariant under monotone transformations. We further leverage our geometric perspective to show that our analysis is optimal. Both monotone invariance and its ability to utilize a low latent dimensionality are key to the empirical success of our algorithms, as demonstrated on synthetic and MuJoCo benchmarks.
              
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Skep6TVYDB&name=original_pdf>
  *


            Conditional Learning of Fair Representations
            <https://openreview.net/forum?id=Hkekl0NFPr>
            <https://openreview.net/pdf?id=Hkekl0NFPr>

    Han Zhao
    <https://openreview.net/profile?email=han.zhao%40cs.cmu.edu>, Amanda
    Coston <https://openreview.net/profile?email=acoston%40cs.cmu.edu>,
    Tameem Adel
    <https://openreview.net/profile?email=tah47%40cam.ac.uk>, Geoffrey
    J. Gordon <https://openreview.net/profile?email=ggordon%40cs.cmu.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#Hkekl0NFPr-details-164>
      o *Keywords:* algorithmic fairness, representation learning
      o *TL;DR:* We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups.
      o *Abstract:* We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups in the classification setting. Two key components underpinning the design of our algorithm are balanced error rate and conditional alignment of representations. We show how these two components contribute to ensuring accuracy parity and equalized false-positive and false-negative rates across groups without impacting demographic parity. Furthermore, we also demonstrate both in theory and on two real-world experiments that the proposed algorithm leads to a better utility-fairness trade-off on balanced datasets compared with existing algorithms on learning fair representations for classification. 
              
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Hkekl0NFPr&name=original_pdf>
  *


            Inductive Matrix Completion Based on Graph Neural Networks
            <https://openreview.net/forum?id=ByxxgCEYDS>
            <https://openreview.net/pdf?id=ByxxgCEYDS>

    Muhan Zhang
    <https://openreview.net/profile?email=muhan%40wustl.edu>, Yixin Chen
    <https://openreview.net/profile?email=chen%40cse.wustl.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#ByxxgCEYDS-details-160>
      o *Keywords:* matrix completion, graph neural network
      o *Abstract:* We propose an inductive matrix completion model without using side information. By factorizing the (rating) matrix into the product of low-dimensional latent embeddings of rows (users) and columns (items), a majority of existing matrix completion methods are transductive, since the learned embeddings cannot generalize to unseen rows/columns or to new matrices. To make matrix completion inductive, most previous works use content (side information), such as user's age or movie's genre, to make predictions. However, high-quality content is not always available, and can be hard to extract. Under the extreme setting where not any side information is available other than the matrix to complete, can we still learn an inductive matrix completion model? In this paper, we propose an Inductive Graph-based Matrix Completion (IGMC) model to address this problem. IGMC trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps these subgraphs to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive -- it can generalize to users/items unseen during the training (given that their interactions exist), and can even transfer to new tasks. Our transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance. Our work demonstrates that: 1) it is possible to train inductive matrix completion models without using side information while achieving similar or better performances than state-of-the-art transductive methods; 2) local graph patterns around a (user, item) pair are effective predictors of the rating this user gives to the item; and 3) Long-range dependencies might not be necessary for modeling recommender systems.
      o *Code:* https://github.com/muhanzhang/IGMC
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=ByxxgCEYDS&name=original_pdf>
  *


            Duration-of-Stay Storage Assignment under Uncertainty
            <https://openreview.net/forum?id=Hkx7xRVYDr>
            <https://openreview.net/pdf?id=Hkx7xRVYDr>

    Michael Lingzhi Li
    <https://openreview.net/profile?email=mlli%40mit.edu>, Elliott Wolf
    <https://openreview.net/profile?email=ewolf%40lineagelogistics.com>,
    Daniel Wintz
    <https://openreview.net/profile?email=dwintz%40lineagelogistics.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 20 Replies
    Show details <#Hkx7xRVYDr-details-911>
      o *Keywords:* Storage Assignment, Deep Learning, Duration-of-Stay, Application, Natural Language Processing, Parallel Network
      o *TL;DR:* We develop a new storage assignment framework with a novel neural network that enables large efficiency gains in the warehouse.
      o *Abstract:* Storage assignment, the act of choosing what goods are placed in what locations in a warehouse, is a central problem of supply chain logistics. Past literature has shown that the optimal method to assign pallets is to arrange them in increasing duration of stay in the warehouse (the Duration-of-Stay, or DoS, method), but the methodology requires perfect prior knowledge of DoS for each pallet, which is unknown and uncertain under realistic conditions. Attempts to predict DoS have largely been unfruitful due to the multi-valuedness nature (every shipment contains multiple identical pallets with different DoS) and data sparsity induced by lack of matching historical conditions. In this paper, we introduce a new framework for storage assignment that provides a solution to the DoS prediction problem through a distributional reformulation and a novel neural network, ParallelNet. Through collaboration with a world-leading cold storage company, we show that the system is able to predict DoS with a MAPE of 29%, a decrease of ~30% compared to a CNN-LSTM model, and suffers less performance decay into the future. The framework is then integrated into a first-of-its-kind Storage Assignment system, which is being deployed in warehouses across United States, with initial results showing up to 21% in labor savings. We also release the first publicly available set of warehousing records to facilitate research into this central problem.
      o *Code:* https://anonymous.4open.science/r/8de2111c-d496-423e-86f3-b5e31792bead/
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Hkx7xRVYDr&name=original_pdf>
  *


            Emergence of functional and structural properties of the
            head direction system by optimization of recurrent neural
            networks <https://openreview.net/forum?id=HklSeREtPB>
            <https://openreview.net/pdf?id=HklSeREtPB>

    Christopher J. Cueva
    <https://openreview.net/profile?email=ccueva%40gmail.com>, Peter Y.
    Wang
    <https://openreview.net/profile?email=peterwang724%40gmail.com>,
    Matthew Chin
    <https://openreview.net/profile?email=mattchin35%40gmail.com>,
    Xue-Xin Wei <https://openreview.net/profile?email=weixxpku%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#HklSeREtPB-details-690>
      o *TL;DR:* Artificial neural networks trained with gradient descent are capable of recapitulating both realistic neural activity and the anatomical organization of a biological circuit.
      o *Abstract:* Recent work suggests goal-driven training of neural networks can be used to model neural activity in the brain. While response properties of neurons in artificial neural networks bear similarities to those in the brain, the network architectures are often constrained to be different. Here we ask if a neural network can recover both neural representations and, if the architecture is unconstrained and optimized, also the anatomical properties of neural circuits. We demonstrate this in a system where the connectivity and the functional organization have been characterized, namely, the head direction circuit of the rodent and fruit fly. We trained recurrent neural networks (RNNs) to estimate head direction through integration of angular velocity. We found that the two distinct classes of neurons observed in the head direction system, the Compass neurons and the Shifter neurons, emerged naturally in artificial neural networks as a result of training. Furthermore, connectivity analysis and in-silico neurophysiology revealed structural and mechanistic similarities between artificial networks and the head direction system. Overall, our results show that optimization of RNNs in a goal-driven task can recapitulate the structure and function of biological circuits, suggesting that artificial neural networks can be used to study the brain at the level of both neural activity and anatomical organization.
      o *Keywords:* recurrent network, head direction system, neural circuits, neural coding
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HklSeREtPB&name=original_pdf>
  *


            Deep neuroethology of a virtual rodent
            <https://openreview.net/forum?id=SyxrxR4KPS>
            <https://openreview.net/pdf?id=SyxrxR4KPS>

    Josh Merel
    <https://openreview.net/profile?email=jsmerel%40google.com>, Diego
    Aldarondo
    <https://openreview.net/profile?email=diegoaldarondo%40g.harvard.edu>,
    Jesse Marshall
    <https://openreview.net/profile?email=jesse_d_marshall%40fas.harvard.edu>,
    Yuval Tassa
    <https://openreview.net/profile?email=tassa%40google.com>, Greg
    Wayne <https://openreview.net/profile?email=gregwayne%40google.com>,
    Bence Olveczky
    <https://openreview.net/profile?email=olveczky%40fas.harvard.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#SyxrxR4KPS-details-753>
      o *Keywords:* computational neuroscience, motor control, deep RL
      o *TL;DR:* We built a physical simulation of a rodent, trained it to solve a set of tasks, and analyzed the resulting networks.
      o *Abstract:* Parallel developments in neuroscience and deep learning have led to mutually productive exchanges, pushing our understanding of real and artificial neural networks in sensory and cognitive systems. However, this interaction between fields is less developed in the study of motor control. In this work, we develop a virtual rodent as a platform for the grounded study of motor activity in artificial models of embodied control. We then use this platform to study motor activity across contexts by training a model to solve four complex tasks. Using methods familiar to neuroscientists, we describe the behavioral representations and algorithms employed by different layers of the network using a neuroethological approach to characterize motor activity relative to the rodent's behavior and goals. We find that the model uses two classes of representations which respectively encode the task-specific behavioral strategies and task-invariant behavioral kinematics. These representations are reflected in the sequential activity and population dynamics of neural subpopulations. Overall, the virtual rodent facilitates grounded collaborations between deep reinforcement learning and motor neuroscience.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SyxrxR4KPS&name=original_pdf>
  *


            Doubly Robust Bias Reduction in Infinite Horizon Off-Policy
            Estimation <https://openreview.net/forum?id=S1glGANtDr>
            <https://openreview.net/pdf?id=S1glGANtDr>

    Ziyang Tang*
    <https://openreview.net/profile?email=ztang%40cs.utexas.edu>, Yihao
    Feng* <https://openreview.net/profile?email=yihao%40cs.utexas.edu>,
    Lihong Li
    <https://openreview.net/profile?email=lihongli.cs%40gmail.com>,
    Dengyong Zhou
    <https://openreview.net/profile?email=dennyzhou%40google.com>, Qiang
    Liu <https://openreview.net/profile?email=lqiang%40cs.utexas.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 14 Replies
    Show details <#S1glGANtDr-details-240>
      o *TL;DR:* We develop a new doubly robust estimator based on the infinite horizon density ratio and off policy value estimation.
      o *Abstract:* Infinite horizon off-policy policy evaluation is a highly challenging task due to the excessively large variance of typical importance sampling (IS) estimators. Recently, Liu et al. (2018) proposed an approach that significantly reduces the variance of infinite-horizon off-policy evaluation by estimating the stationary density ratio, but at the cost of introducing potentially high risks due to the error in density ratio estimation. In this paper, we develop a bias-reduced augmentation of their method, which can take advantage of a learned value function to obtain higher accuracy. Our method is doubly robust in that the bias vanishes when either the density ratio or value function estimation is perfect.  In general, when either of them is accurate, the bias can also be reduced. Both theoretical and empirical results show that our method yields significant advantages over previous methods.
      o *Keywords:* off-policy evaluation, infinite horizon, doubly robust, reinforcement learning
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1glGANtDr&name=original_pdf>
  *


            Learning Compositional Koopman Operators for Model-Based
            Control <https://openreview.net/forum?id=H1ldzA4tPr>
            <https://openreview.net/pdf?id=H1ldzA4tPr>

    Yunzhu Li <https://openreview.net/profile?email=liyunzhu%40mit.edu>,
    Hao He <https://openreview.net/profile?email=haohe%40mit.edu>,
    Jiajun Wu
    <https://openreview.net/profile?email=jiajunwu.cs%40gmail.com>, Dina
    Katabi <https://openreview.net/profile?email=dina%40csail.mit.edu>,
    Antonio Torralba
    <https://openreview.net/profile?email=torralba%40csail.mit.edu>
    25 Sep 2019 (modified: 27 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#H1ldzA4tPr-details-840>
      o *Keywords:* Koopman operators, graph neural networks, compositionality
      o *TL;DR:* Learning compositional Koopman operators for efficient system identification and model-based control.
      o *Abstract:* Finding an embedding space for a linear approximation of a nonlinear dynamical system enables efficient system identification and control synthesis. The Koopman operator theory lays the foundation for identifying the nonlinear-to-linear coordinate transformations with data-driven methods. Recently, researchers have proposed to use deep neural networks as a more expressive class of basis functions for calculating the Koopman operators. These approaches, however, assume a fixed dimensional state space; they are therefore not applicable to scenarios with a variable number of objects. In this paper, we propose to learn compositional Koopman operators, using graph neural networks to encode the state into object-centric embeddings and using a block-wise linear transition matrix to regularize the shared structure across objects. The learned dynamics can quickly adapt to new environments of unknown physical parameters and produce control signals to achieve a specified goal. Our experiments on manipulating ropes and controlling soft robots show that the proposed method has better efficiency and generalization ability than existing baselines.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1ldzA4tPr&name=original_pdf>
  *


            CLEVRER: Collision Events for Video Representation and
            Reasoning <https://openreview.net/forum?id=HkxYzANYDB>
            <https://openreview.net/pdf?id=HkxYzANYDB>

    Kexin Yi*
    <https://openreview.net/profile?email=kyi%40g.harvard.edu>, Chuang
    Gan*
    <https://openreview.net/profile?email=ganchuang1990%40gmail.com>,
    Yunzhu Li <https://openreview.net/profile?email=liyunzhu%40mit.edu>,
    Pushmeet Kohli
    <https://openreview.net/profile?email=pushmeet%40google.com>, Jiajun
    Wu <https://openreview.net/profile?email=jiajunwu%40mit.edu>,
    Antonio Torralba
    <https://openreview.net/profile?email=torralba%40mit.edu>, Joshua B.
    Tenenbaum <https://openreview.net/profile?email=jbt%40mit.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#HkxYzANYDB-details-222>
      o *TL;DR:* We present a diagnostic dataset for systematic study of temporal and casual reasoning in videos. 
      o *Abstract:* The ability to reason about temporal and causal events from videos lies at the core of human intelligence. Most video reasoning benchmarks, however, focus on pattern recognition from complex visual and language input, instead of on causal structure. We study the complementary problem, exploring the temporal and causal structures behind videos of objects with simple visual appearance. To this end, we introduce the CoLlision Events for Video REpresentation and Reasoning (CLEVRER) dataset, a  diagnostic video dataset for systematic evaluation of computational models on a wide range of reasoning tasks.  Motivated by the theory of human casual judgment, CLEVRER includes four types of question:  descriptive (e.g., ‘what color’), explanatory (‘what’s responsible for’), predictive (‘what will happen next’), and counterfactual (‘what if’).  We evaluate various state-of-the-art models for visual reasoning on our benchmark. While these models thrive on the perception-based task (descriptive), they perform poorly on the causal tasks (explanatory, predictive and counterfactual), suggesting that a principled approach for causal reasoning should incorporate the capability of both perceiving complex visual and language inputs, and understanding the underlying dynamics and causal relations. We also study an oracle model that explicitly combines these components via symbolic representations. 
      o *Keywords:* Neuro-symbolic, Reasoning
      o *Code:* http://clevrer.csail.mit.edu/
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HkxYzANYDB&name=original_pdf>
  *


            The Logical Expressiveness of Graph Neural Networks
            <https://openreview.net/forum?id=r1lZ7AEKvB>
            <https://openreview.net/pdf?id=r1lZ7AEKvB>

    Pablo Barceló
    <https://openreview.net/profile?email=pbarcelo%40gmail.com>, Egor V.
    Kostylev
    <https://openreview.net/profile?email=egor.kostylev%40cs.ox.ac.uk>,
    Mikael Monet
    <https://openreview.net/profile?email=mikael.monet%40imfd.cl>, Jorge
    Pérez
    <https://openreview.net/profile?email=jorge.perez.rojas%40gmail.com>, Juan
    Reutter
    <https://openreview.net/profile?email=juan.reutter%40gmail.com>,
    Juan Pablo Silva
    <https://openreview.net/profile?email=jpsilvapena%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#r1lZ7AEKvB-details-888>
      o *TL;DR:* We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.
      o *Abstract:* The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.
      o *Code:* https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/
      o *Keywords:* Graph Neural Networks, First Order Logic, Expressiveness
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=r1lZ7AEKvB&name=original_pdf>
  *


            The Break-Even Point on Optimization Trajectories of Deep
            Neural Networks <https://openreview.net/forum?id=r1g87C4KwB>
            <https://openreview.net/pdf?id=r1g87C4KwB>

    Stanislaw Jastrzebski
    <https://openreview.net/profile?email=staszek.jastrzebski%40gmail.com>,
    Maciej Szymczak
    <https://openreview.net/profile?email=msz93%40o2.pl>, Stanislav Fort
    <https://openreview.net/profile?email=stanislav.fort%40gmail.com>,
    Devansh Arpit
    <https://openreview.net/profile?email=devansharpit%40gmail.com>,
    Jacek Tabor
    <https://openreview.net/profile?email=jcktbr%40gmail.com>, Kyunghyun
    Cho* <https://openreview.net/profile?email=kyunghyun.cho%40nyu.edu>,
    Krzysztof Geras*
    <https://openreview.net/profile?email=k.j.geras%40nyu.edu>
    25 Sep 2019 (modified: 28 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#r1g87C4KwB-details-728>
      o *TL;DR:* In the early phase of training of deep neural networks there exists a "break-even point" which determines properties of the entire optimization trajectory.
      o *Abstract:* The early phase of training of deep neural networks is critical for their final performance. In this work, we study how the hyperparameters of stochastic gradient descent (SGD) used in the early phase of training affect the rest of the optimization trajectory. We argue for the existence of the "``break-even" point on this trajectory, beyond which the curvature of the loss surface and noise in the gradient are implicitly regularized by SGD. In particular, we demonstrate on multiple classification tasks that using a large learning rate in the initial phase of training reduces the variance of the gradient, and improves the conditioning of the covariance of gradients. These effects are beneficial from the optimization perspective and become visible after the break-even point. Complementing prior work, we also show that using a low learning rate results in bad conditioning of the loss surface even for a neural network with batch normalization layers. In short, our work shows that key properties of the loss surface are strongly influenced by SGD in the early phase of training. We argue that studying the impact of the identified effects on generalization is a promising future direction.
      o *Keywords:* generalization, sgd, learning rate, batch size, hessian, curvature, trajectory, optimization
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=r1g87C4KwB&name=original_pdf>
  *


            ALBERT: A Lite BERT for Self-supervised Learning of Language
            Representations <https://openreview.net/forum?id=H1eA7AEtvS>
            <https://openreview.net/pdf?id=H1eA7AEtvS>

    Zhenzhong Lan
    <https://openreview.net/profile?email=lanzhzh%40google.com>, Mingda
    Chen <https://openreview.net/profile?email=mchen%40ttic.edu>,
    Sebastian Goodman
    <https://openreview.net/profile?email=seabass%40google.com>, Kevin
    Gimpel <https://openreview.net/profile?email=kgimpel%40ttic.edu>,
    Piyush Sharma
    <https://openreview.net/profile?email=piyushsharma%40google.com>,
    Radu Soricut
    <https://openreview.net/profile?email=rsoricut%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 32 Replies
    Show details <#H1eA7AEtvS-details-634>
      o *Keywords:* Natural Language Processing, BERT, Representation Learning
      o *TL;DR:* A new pretraining method that establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large. 
      o *Abstract:* Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems,  we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT~\citep{devlin2018bert}. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.
      o *Code:* https://github.com/google-research/ALBERT
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1eA7AEtvS&name=original_pdf>
  *


            Disentangling neural mechanisms for perceptual grouping
            <https://openreview.net/forum?id=HJxrVA4FDS>
            <https://openreview.net/pdf?id=HJxrVA4FDS>

    Junkyung Kim*
    <https://openreview.net/profile?email=junkyung_kim%40brown.edu>,
    Drew Linsley*
    <https://openreview.net/profile?email=drew_linsley%40brown.edu>,
    Kalpit Thakkar
    <https://openreview.net/profile?email=kalpit_thakkar%40brown.edu>,
    Thomas Serre
    <https://openreview.net/profile?email=thomas_serre%40brown.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#HJxrVA4FDS-details-68>
      o *Keywords:* Perceptual grouping, visual cortex, recurrent feedback, horizontal connections, top-down connections
      o *TL;DR:* Horizontal and top-down feedback connections are responsible for complementary perceptual grouping strategies in biological and recurrent vision systems.
      o *Abstract:* Forming perceptual groups and individuating objects in visual scenes is an essential step towards visual intelligence. This ability is thought to arise in the brain from computations implemented by bottom-up, horizontal, and top-down connections between neurons. However, the relative contributions of these connections to perceptual grouping are poorly understood. We address this question by systematically evaluating neural network architectures featuring combinations bottom-up, horizontal, and top-down connections on two synthetic visual tasks, which stress low-level "Gestalt" vs. high-level object cues for perceptual grouping. We show that increasing the difficulty of either task strains learning for networks that rely solely on bottom-up connections. Horizontal connections resolve straining on tasks with Gestalt cues by supporting incremental grouping, whereas top-down connections rescue learning on tasks with high-level object cues by modifying coarse predictions about the position of the target object. Our findings dissociate the computational roles of bottom-up, horizontal and top-down connectivity, and demonstrate how a model featuring all of these interactions can more flexibly learn to form perceptual groups.
      o *Code:* https://bit.ly/2wdQYGd
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HJxrVA4FDS&name=original_pdf>
  *


            Learning to Plan in High Dimensions via Neural
            Exploration-Exploitation Trees
            <https://openreview.net/forum?id=rJgJDAVKvB>
            <https://openreview.net/pdf?id=rJgJDAVKvB>

    Binghong Chen
    <https://openreview.net/profile?email=binghong%40gatech.edu>, Bo Dai
    <https://openreview.net/profile?email=bodai%40google.com>, Qinjie
    Lin
    <https://openreview.net/profile?email=qinjielin2018%40u.northwestern.edu>,
    Guo Ye
    <https://openreview.net/profile?email=guoye2018%40u.northwestern.edu>,
    Han Liu
    <https://openreview.net/profile?email=hanliu%40northwestern.edu>, Le
    Song <https://openreview.net/profile?email=lsong%40cc.gatech.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#rJgJDAVKvB-details-1>
      o *Keywords:* learning to plan, representation learning, learning to design algorithm, reinforcement learning, meta learning
      o *TL;DR:* We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.
      o *Abstract:* We propose a meta path planning algorithm named \emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \emph{exploration} and \emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.
      o *Code:* https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJgJDAVKvB&name=original_pdf>
  *


            Symplectic Recurrent Neural Networks
            <https://openreview.net/forum?id=BkgYPREtPr>
            <https://openreview.net/pdf?id=BkgYPREtPr>

    Zhengdao Chen
    <https://openreview.net/profile?email=zc1216%40nyu.edu>, Jianyu
    Zhang <https://openreview.net/profile?email=edzhang%40tju.edu.cn>,
    Martin Arjovsky
    <https://openreview.net/profile?email=martinarjovsky%40gmail.com>,
    Léon Bottou <https://openreview.net/profile?email=leonb%40fb.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#BkgYPREtPr-details-550>
      o *Keywords:* Hamiltonian systems, learning physical laws, symplectic integrators, recurrent neural networks, inverse problems
      o *Abstract:* We propose Symplectic Recurrent Neural Networks (SRNNs) as learning algorithms that capture the dynamics of physical systems from observed trajectories. SRNNs model the Hamiltonian function of the system by a neural networks, and leverage symplectic integration, multiple-step training and initial state optimization to address the challenging numerical issues associated with Hamiltonian systems. We show SRNNs succeed reliably on complex and noisy Hamiltonian systems. Finally, we show how to augment the SRNN integration scheme in order to handle stiff dynamical systems such as bouncing billiards.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BkgYPREtPr&name=original_pdf>
  *


            Asymptotics of Wide Networks from Feynman Diagrams
            <https://openreview.net/forum?id=S1gFvANKDS>
            <https://openreview.net/pdf?id=S1gFvANKDS>

    Ethan Dyer
    <https://openreview.net/profile?email=edyer%40google.com>, Guy
    Gur-Ari <https://openreview.net/profile?email=guyga%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#S1gFvANKDS-details-248>
      o *TL;DR:* A general method for computing the asymptotic behavior of wide networks using Feynman diagrams
      o *Abstract:* Understanding the asymptotic behavior of wide networks is of considerable interest. In this work, we present a general method for analyzing this large width behavior. The method is an adaptation of Feynman diagrams, a standard tool for computing multivariate Gaussian integrals. We apply our method to study training dynamics, improving existing bounds and deriving new results on wide network evolution during stochastic gradient descent. Going beyond the strict large width limit, we present closed-form expressions for higher-order terms governing wide network training, and test these predictions empirically.
              
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1gFvANKDS&name=original_pdf>
  *


            Learning The Difference That Makes A Difference With
            Counterfactually-Augmented Data
            <https://openreview.net/forum?id=Sklgs0NFvr>
            <https://openreview.net/pdf?id=Sklgs0NFvr>

    Divyansh Kaushik
    <https://openreview.net/profile?email=dkaushik%40cs.cmu.edu>, Eduard
    Hovy <https://openreview.net/profile?email=hovy%40cmu.edu>, Zachary
    Lipton <https://openreview.net/profile?email=zlipton%40cmu.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#Sklgs0NFvr-details-367>
      o *TL;DR:* Humans in the loop revise documents to accord with counterfactual labels, resulting resource helps to reduce reliance on spurious associations.
      o *Abstract:* Despite alarm over the reliance of machine learning systems on so-called spurious patterns, the term lacks coherent meaning in standard statistical frameworks. However, the language of causality offers clarity: spurious associations are due to confounding (e.g., a common cause), but not direct or indirect causal effects. In this paper, we focus on natural language processing, introducing methods and resources  for training models less sensitive to spurious patterns. Given documents and their initial labels, we task humans with revising each document so that it (i) accords with a counterfactual target label; (ii) retains internal coherence;  and (iii) avoids unnecessary changes. Interestingly, on sentiment analysis and natural language inference tasks, classifiers trained on original data fail on their  counterfactually-revised counterparts and vice versa. Classifiers trained on combined datasets  perform remarkably well, just shy of those specialized to either domain. While classifiers trained on either original or manipulated data alone  are sensitive to spurious features (e.g., mentions of genre), models trained on the combined data are less sensitive to this signal. Both datasets are publicly available.
      o *Keywords:* humans in the loop, annotation artifacts, text classification, sentiment analysis, natural language inference
      o *Code:* https://github.com/dkaushik96/counterfactually-augmented-data
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Sklgs0NFvr&name=original_pdf>
  *


            Is a Good Representation Sufficient for Sample Efficient
            Reinforcement Learning?
            <https://openreview.net/forum?id=r1genAVKPB>
            <https://openreview.net/pdf?id=r1genAVKPB>

    Simon S. Du <https://openreview.net/profile?email=ssdu%40ias.edu>,
    Sham M. Kakade
    <https://openreview.net/profile?email=sham%40cs.washington.edu>,
    Ruosong Wang
    <https://openreview.net/profile?email=ruosongw%40andrew.cmu.edu>,
    Lin F. Yang
    <https://openreview.net/profile?email=linyang%40ee.ucla.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#r1genAVKPB-details-604>
      o *Keywords:* reinforcement learning, function approximation, lower bound, representation
      o *TL;DR:* Exponential lower bounds for value-based and policy-based reinforcement learning with function approximation.
      o *Abstract:* Modern deep learning methods provide effective means to learn good representations. However, is a good representation itself sufficient for sample efficient reinforcement learning? This question has largely been studied only with respect to (worst-case) approximation error, in the more classical approximate dynamic programming literature. With regards to the statistical viewpoint, this question is largely unexplored, and the extant body of literature mainly focuses on conditions which \emph{permit} sample efficient reinforcement learning with little understanding of what are \emph{necessary} conditions for efficient reinforcement learning.
              This work shows that, from the statistical viewpoint, the situation is far subtler than suggested by the more traditional approximation viewpoint, where the requirements on the representation that suffice for sample efficient RL are even more stringent. Our main results provide sharp thresholds for reinforcement learning methods, showing that there are hard limitations on what constitutes good function approximation (in terms of the dimensionality of the representation), where we focus on natural representational conditions relevant to value-based, model-based, and policy-based learning. These lower bounds highlight that having a good (value-based, model-based, or policy-based) representation in and of itself is insufficient for efficient reinforcement learning, unless the quality of this approximation passes certain hard thresholds. Furthermore, our lower bounds also imply exponential separations on the sample complexity between 1) value-based learning with perfect representation and value-based learning with a good-but-not-perfect representation, 2) value-based learning and policy-based learning, 3) policy-based learning and supervised learning and 4) reinforcement learning and imitation learning.   
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=r1genAVKPB&name=original_pdf>
  *


            Simplified Action Decoder for Deep Multi-Agent Reinforcement
            Learning <https://openreview.net/forum?id=B1xm3RVtwB>
            <https://openreview.net/pdf?id=B1xm3RVtwB>

    Hengyuan Hu
    <https://openreview.net/profile?email=hengyuan%40fb.com>, Jakob N
    Foerster
    <https://openreview.net/profile?email=jakobfoerster%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#B1xm3RVtwB-details-714>
      o *TL;DR:* We develop Simplified Action Decoder, a simple MARL algorithm that beats previous SOTA on Hanabi by a big margin across 2- to 5-player games.
      o *Abstract:* In recent years we have seen fast progress on a number of benchmark problems in AI, with modern methods achieving near or super human performance in Go, Poker and Dota. One common aspect of all of these challenges is that they are by design adversarial or, technically speaking, zero-sum. In contrast to these settings, success in the real world commonly requires humans to collaborate and communicate with others, in settings that are, at least partially, cooperative. In the last year, the card game Hanabi has been established as a new benchmark environment for AI to fill this gap. In particular, Hanabi is interesting to humans since it is entirely focused on theory of mind, i.e. the ability to effectively reason over the intentions, beliefs and point of view of other agents when observing their actions. Learning to be informative when observed by others is an interesting challenge for Reinforcement Learning (RL): Fundamentally, RL requires agents to explore in order to discover good policies. However, when done naively, this randomness will inherently make their actions less informative to others during training. We present a new deep multi-agent RL method, the Simplified Action Decoder (SAD), which resolves this contradiction exploiting the centralized training phase. During training SAD allows other agents to not only observe the (exploratory) action chosen, but agents instead also observe the greedy action of their team mates. By combining this simple intuition with an auxiliary task for state prediction and best practices for multi-agent learning, SAD establishes a new state of the art for 2-5 players on the self-play part of the Hanabi challenge.
      o *Code:* https://bit.ly/2mBJLyk
      o *Keywords:* multi-agent RL, theory of mind
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1xm3RVtwB&name=original_pdf>
  *


            Network Deconvolution
            <https://openreview.net/forum?id=rkeu30EtvS>
            <https://openreview.net/pdf?id=rkeu30EtvS>

    Chengxi Ye
    <https://openreview.net/profile?email=yechengxi%40gmail.com>,
    Matthew Evanusa
    <https://openreview.net/profile?email=mevanusa%40umd.edu>, Hua He
    <https://openreview.net/profile?email=huah%40umd.edu>, Anton
    Mitrokhin <https://openreview.net/profile?email=amitrokh%40umd.edu>,
    Tom Goldstein
    <https://openreview.net/profile?email=tomg%40cs.umd.edu>, James A.
    Yorke <https://openreview.net/profile?email=yorke%40umd.edu>,
    Cornelia Fermuller
    <https://openreview.net/profile?email=fer%40umiacs.umd.edu>, Yiannis
    Aloimonos <https://openreview.net/profile?email=yiannis%40cs.umd.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#rkeu30EtvS-details-428>
      o *TL;DR:* We propose a method called network deconvolution that resembles animal vision system to train convolution networks better.
      o *Abstract:* Convolution is a central operation in Convolutional Neural Networks (CNNs), which applies a kernel to overlapping regions shifted across the image. However, because of the strong  correlations in real-world image data, convolutional kernels are in effect re-learning redundant data. In this work, we show that this redundancy has made neural network training challenging, and propose network deconvolution, a procedure which optimally removes pixel-wise and channel-wise correlations before the data is fed into each layer. Network deconvolution can be efficiently calculated at a fraction of the computational cost of a convolution layer. We also show that the deconvolution filters in the first layer of the network resemble the center-surround structure found in biological neurons in the visual regions of the brain. Filtering with such kernels results in a sparse representation, a desired property that has been missing in the training of neural networks. Learning from the sparse representation promotes faster convergence and superior results without the use of batch normalization. We apply our network deconvolution operation to 10 modern neural network models by replacing batch normalization within each. Extensive experiments show that the network deconvolution operation is able to deliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST, Fashion-MNIST, Cityscapes, and ImageNet datasets.
      o *Code:* https://github.com/yechengxi/deconvolution
      o *Keywords:* convolutional networks, network deconvolution, whitening
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rkeu30EtvS&name=original_pdf>
  *


            Neural Symbolic Reader: Scalable Integration of Distributed
            and Symbolic Representations for Reading Comprehension
            <https://openreview.net/forum?id=ryxjnREFwH>
            <https://openreview.net/pdf?id=ryxjnREFwH>

    Xinyun Chen
    <https://openreview.net/profile?email=xinyun.chen%40berkeley.edu>,
    Chen Liang
    <https://openreview.net/profile?email=crazydonkey%40google.com>,
    Adams Wei Yu
    <https://openreview.net/profile?email=adamsyuwei%40google.com>,
    Denny Zhou
    <https://openreview.net/profile?email=dennyzhou%40google.com>, Dawn
    Song
    <https://openreview.net/profile?email=dawnsong.travel%40gmail.com>,
    Quoc V. Le <https://openreview.net/profile?email=qvl%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#ryxjnREFwH-details-548>
      o *Abstract:* Integrating distributed representations with symbolic operations is essential for reading comprehension requiring complex reasoning, such as counting, sorting and arithmetics, but most existing approaches are hard to scale to more domains or more complex reasoning. In this work, we propose the Neural Symbolic Reader (NeRd), which includes a reader, e.g., BERT, to encode the passage and question, and a programmer, e.g., LSTM, to generate a program that is executed to produce the answer. Compared to previous works, NeRd is more scalable in two aspects: (1) domain-agnostic, i.e., the same neural architecture works for different domains; (2) compositional, i.e., when needed, complex programs can be generated by recursively applying the predefined operators, which become executable and interpretable representations for more complex reasoning. Furthermore, to overcome the challenge of training NeRd with weak supervision, we apply data augmentation techniques and hard Expectation-Maximization (EM) with thresholding. On DROP, a challenging reading comprehension dataset that requires discrete reasoning, NeRd achieves 1.37%/1.18% absolute improvement over the state-of-the-art on EM/F1 metrics. With the same architecture, NeRd significantly outperforms the baselines on MathQA, a math problem benchmark that requires multiple steps of reasoning, by 25.5% absolute increment on accuracy when trained on all the annotated programs. More importantly, NeRd still beats the baselines even when only 20% of the program annotations are given.
      o *Keywords:* neural symbolic, reading comprehension, question answering
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=ryxjnREFwH&name=original_pdf>
  *


            Real or Not Real, that is the Question
            <https://openreview.net/forum?id=B1lPaCNtPB>
            <https://openreview.net/pdf?id=B1lPaCNtPB>

    Yuanbo Xiangli*
    <https://openreview.net/profile?email=xy019%40ie.cuhk.edu.hk>, Yubin
    Deng*
    <https://openreview.net/profile?email=danny.s.deng.ds%40gmail.com>,
    Bo Dai*
    <https://openreview.net/profile?email=doubledaibo%40gmail.com>, Chen
    Change Loy
    <https://openreview.net/profile?email=ccloy%40ntu.edu.sg>, Dahua Lin
    <https://openreview.net/profile?email=dhlin%40ie.cuhk.edu.hk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#B1lPaCNtPB-details-734>
      o *Keywords:* GAN, generalization, realness, loss function
      o *Abstract:* While generative adversarial networks (GAN) have been widely adopted in various topics, in this paper we generalize the standard GAN to a new perspective by treating realness as a random variable that can be estimated from multiple angles. In this generalized framework, referred to as RealnessGAN, the discriminator outputs a distribution as the measure of realness. While RealnessGAN shares similar theoretical guarantees with the standard GAN, it provides more insights on adversarial learning. More importantly, compared to multiple baselines, RealnessGAN provides stronger guidance for the generator, achieving improvements on both synthetic and real-world datasets. Moreover, it enables the basic DCGAN architecture to generate realistic images at 1024*1024 resolution when trained from scratch.
      o *Code:* https://github.com/kam1107/RealnessGAN
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1lPaCNtPB&name=original_pdf>
  *


            Dream to Control: Learning Behaviors by Latent Imagination
            <https://openreview.net/forum?id=S1lOTC4tDS>
            <https://openreview.net/pdf?id=S1lOTC4tDS>

    Danijar Hafner
    <https://openreview.net/profile?email=mail%40danijar.com>, Timothy
    Lillicrap
    <https://openreview.net/profile?email=countzero%40google.com>, Jimmy
    Ba <https://openreview.net/profile?email=jba%40cs.toronto.edu>,
    Mohammad Norouzi
    <https://openreview.net/profile?email=mnorouzi%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 15 Replies
    Show details <#S1lOTC4tDS-details-62>
      o *TL;DR:* We present Dreamer, an agent that learns long-horizon behaviors purely by latent imagination using analytic value gradients.
      o *Abstract:* Learned world models summarize an agent's experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.
      o *Keywords:* world model, latent dynamics, imagination, planning by backprop, policy optimization, planning, reinforcement learning, control, representations, latent variable model, visual control, value function
      o *Code:* https://danijar.com/dreamer
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf>
  *


            A Probabilistic Formulation of Unsupervised Text Style
            Transfer <https://openreview.net/forum?id=HJlA0C4tPS>
            <https://openreview.net/pdf?id=HJlA0C4tPS>

    Junxian He
    <https://openreview.net/profile?email=junxianh%40cs.cmu.edu>, Xinyi
    Wang <https://openreview.net/profile?email=xinyiw1%40cs.cmu.edu>,
    Graham Neubig
    <https://openreview.net/profile?email=gneubig%40cs.cmu.edu>, Taylor
    Berg-Kirkpatrick
    <https://openreview.net/profile?email=tberg%40eng.ucsd.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#HJlA0C4tPS-details-962>
      o *TL;DR:* We formulate a probabilistic latent sequence model to tackle unsupervised text style transfer, and show its effectiveness across a suite of unsupervised text style transfer tasks. 
      o *Abstract:* We present a deep generative model for unsupervised text style transfer that unifies previously proposed non-generative techniques. Our probabilistic approach models non-parallel data from two domains as a partially observed parallel corpus. By hypothesizing a parallel latent sequence that generates each observed sequence, our model learns to transform sequences from one domain to another in a completely unsupervised fashion. In contrast with traditional generative sequence models (e.g. the HMM), our model makes few assumptions about the data it generates: it uses a recurrent language model as a prior and an encoder-decoder as a transduction distribution. While computation of marginal data likelihood is intractable in this model class, we show that amortized variational inference admits a practical surrogate. Further, by drawing connections between our variational objective and other recent unsupervised style transfer and machine translation techniques, we show how our probabilistic view can unify some known non-generative objectives such as backtranslation and adversarial loss. Finally, we demonstrate the effectiveness of our method on a wide range of unsupervised style transfer tasks, including sentiment transfer, formality transfer, word decipherment, author imitation, and related language translation. Across all style transfer tasks, our approach yields substantial gains over state-of-the-art non-generative baselines, including the state-of-the-art unsupervised machine translation techniques that our approach generalizes. Further, we conduct experiments on a standard unsupervised machine translation task and find that our unified approach matches the current state-of-the-art.
      o *Keywords:* unsupervised text style transfer, deep latent sequence model
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HJlA0C4tPS&name=original_pdf>
  *


            Emergent Tool Use From Multi-Agent Autocurricula
            <https://openreview.net/forum?id=SkxpxJBKwS>
            <https://openreview.net/pdf?id=SkxpxJBKwS>

    Bowen Baker
    <https://openreview.net/profile?email=bowen%40openai.com>, Ingmar
    Kanitscheider
    <https://openreview.net/profile?email=ingmar%40openai.com>, Todor
    Markov <https://openreview.net/profile?email=todor%40openai.com>, Yi
    Wu <https://openreview.net/profile?email=jxwuyi%40openai.com>, Glenn
    Powell <https://openreview.net/profile?email=glenn%40openai.com>,
    Bob McGrew
    <https://openreview.net/profile?email=bmcgrew%40openai.com>, Igor
    Mordatch <https://openreview.net/profile?email=imordatch%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#SkxpxJBKwS-details-768>
      o *Abstract:* Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a self-supervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific intelligence tests.
      o *Code:* https://github.com/openai/multi-agent-emergence-environments
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SkxpxJBKwS&name=original_pdf>
  *


            NAS-Bench-201: Extending the Scope of Reproducible Neural
            Architecture Search
            <https://openreview.net/forum?id=HJxyZkBKDr>
            <https://openreview.net/pdf?id=HJxyZkBKDr>

    Xuanyi Dong
    <https://openreview.net/profile?email=xuanyi.dxy%40gmail.com>, Yi
    Yang <https://openreview.net/profile?email=yi.yang%40uts.edu.au>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 22 Replies
    Show details <#HJxyZkBKDr-details-942>
      o *TL;DR:* A NAS benchmark applicable to almost any NAS algorithms.
      o *Abstract:* Neural architecture search (NAS) has achieved breakthrough success in a great number of applications in the past few years.
              It could be time to take a step back and analyze the good and bad aspects in the field of NAS. A variety of algorithms search architectures under different search space. These searched architectures are trained using different setups, e.g., hyper-parameters, data augmentation, regularization. This raises a comparability problem when comparing the performance of various NAS algorithms. NAS-Bench-101 has shown success to alleviate this problem. In this work, we propose an extension to NAS-Bench-101: NAS-Bench-201 with a different search space, results on multiple datasets, and more diagnostic information. NAS-Bench-201 has a fixed search space and provides a unified benchmark for almost any up-to-date NAS algorithms. The design of our search space is inspired by the one used in the most popular cell-based searching algorithms, where a cell is represented as a directed acyclic graph. Each edge here is associated with an operation selected from a predefined operation set. For it to be applicable for all NAS algorithms, the search space defined in NAS-Bench-201 includes all possible architectures generated by 4 nodes and 5 associated operation options, which results in 15,625 neural cell candidates in total. The training log using the same setup and the performance for each architecture candidate are provided for three datasets. This allows researchers to avoid unnecessary repetitive training for selected architecture and focus solely on the search algorithm itself. The training time saved for every architecture also largely improves the efficiency of most NAS algorithms and presents a more computational cost friendly NAS community for a broader range of researchers. We provide additional diagnostic information such as fine-grained loss and accuracy, which can give inspirations to new designs of NAS algorithms. In further support of the proposed NAS-Bench-102, we have analyzed it from many aspects and benchmarked 10 recent NAS algorithms, which verify its applicability.
      o *Keywords:* Neural Architecture Search, AutoML, Benchmark
      o *Code:* https://github.com/D-X-Y/NAS-Bench-201
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HJxyZkBKDr&name=original_pdf>
  *


            Strategies for Pre-training Graph Neural Networks
            <https://openreview.net/forum?id=HJlWWJSFDH>
            <https://openreview.net/pdf?id=HJlWWJSFDH>

    Weihua Hu*
    <https://openreview.net/profile?email=weihuahu%40stanford.edu>,
    Bowen Liu*
    <https://openreview.net/profile?email=liubowen%40stanford.edu>,
    Joseph Gomes
    <https://openreview.net/profile?email=joegomes%40stanford.edu>,
    Marinka Zitnik
    <https://openreview.net/profile?email=marinka%40cs.stanford.edu>,
    Percy Liang
    <https://openreview.net/profile?email=pliang%40cs.stanford.edu>,
    Vijay Pande
    <https://openreview.net/profile?email=pande%40stanford.edu>, Jure
    Leskovec <https://openreview.net/profile?email=jure%40cs.stanford.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 11 Replies
    Show details <#HJlWWJSFDH-details-27>
      o *TL;DR:* We develop a strategy for pre-training Graph Neural Networks (GNNs) and systematically study its effectiveness on multiple datasets, GNN architectures, and diverse downstream tasks.
      o *Abstract:* Many applications of machine learning require a model to make accurate pre-dictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naïve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction.
      o *Keywords:* Pre-training, Transfer learning, Graph Neural Networks
      o *Code:* https://github.com/snap-stanford/pretrain-gnns/
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HJlWWJSFDH&name=original_pdf>
  *


            Behaviour Suite for Reinforcement Learning
            <https://openreview.net/forum?id=rygf-kSYwH>
            <https://openreview.net/pdf?id=rygf-kSYwH>

    Ian Osband
    <https://openreview.net/profile?email=ian.osband%40gmail.com>, Yotam
    Doron <https://openreview.net/profile?email=ydoron%40google.com>,
    Matteo Hessel
    <https://openreview.net/profile?email=mtthss%40google.com>, John
    Aslanides
    <https://openreview.net/profile?email=jaslanides%40google.com>, Eren
    Sezener
    <https://openreview.net/profile?email=esezener%40google.com>, Andre
    Saraiva
    <https://openreview.net/profile?email=andresnds%40google.com>,
    Katrina McKinney
    <https://openreview.net/profile?email=mckinneyk%40google.com>, Tor
    Lattimore
    <https://openreview.net/profile?email=lattimore%40google.com>, Csaba
    Szepesvari
    <https://openreview.net/profile?email=szepi%40google.com>, Satinder
    Singh <https://openreview.net/profile?email=baveja%40google.com>,
    Benjamin Van Roy
    <https://openreview.net/profile?email=benvanroy%40google.com>,
    Richard Sutton
    <https://openreview.net/profile?email=suttonr%40google.com>, David
    Silver
    <https://openreview.net/profile?email=davidsilver%40google.com>,
    Hado Van Hasselt
    <https://openreview.net/profile?email=hado%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 15 Replies
    Show details <#rygf-kSYwH-details-392>
      o *Keywords:* reinforcement learning, benchmark, core issues, scalability, reproducibility
      o *TL;DR:* Bsuite is a collection of carefully-designed experiments that investigate the core capabilities of RL agents.
      o *Abstract:* This paper introduces the Behaviour Suite for Reinforcement Learning, or bsuite for short. bsuite is a collection of carefully-designed experiments that investigate core capabilities of reinforcement learning (RL) agents with two objectives. First, to collect clear, informative and scalable problems that capture key issues in the design of general and efficient learning algorithms. Second, to study agent behaviour through their performance on these shared benchmarks. To complement this effort, we open source this http URL, which automates evaluation and analysis of any agent on bsuite. This library facilitates reproducible and accessible research on the core issues in RL, and ultimately the design of superior learning algorithms. Our code is Python, and easy to use within existing projects. We include examples with OpenAI Baselines, Dopamine as well as new reference implementations. Going forward, we hope to incorporate more excellent experiments from the research community, and commit to a periodic review of bsuite from a committee of prominent researchers.
      o *Code:* https://github.com/deepmind/bsuite
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rygf-kSYwH&name=original_pdf>
  *


            FreeLB: Enhanced Adversarial Training for Natural Language
            Understanding <https://openreview.net/forum?id=BygzbyHFvB>
            <https://openreview.net/pdf?id=BygzbyHFvB>

    Chen Zhu
    <https://openreview.net/profile?email=chenzhu%40cs.umd.edu>, Yu
    Cheng
    <https://openreview.net/profile?email=yu.cheng%40microsoft.com>, Zhe
    Gan <https://openreview.net/profile?email=zhe.gan%40microsoft.com>,
    Siqi Sun
    <https://openreview.net/profile?email=siqi.sun%40microsoft.com>, Tom
    Goldstein <https://openreview.net/profile?email=tomg%40cs.umd.edu>,
    Jingjing Liu
    <https://openreview.net/profile?email=jingjl%40microsoft.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 6 Replies
    Show details <#BygzbyHFvB-details-344>
      o *Abstract:* Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.
      o *Code:* https://github.com/zhuchen03/FreeLB
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BygzbyHFvB&name=original_pdf>
  *


            Kernelized Wasserstein Natural Gradient
            <https://openreview.net/forum?id=Hklz71rYvS>
            <https://openreview.net/pdf?id=Hklz71rYvS>

    M Arbel
    <https://openreview.net/profile?email=michael.n.arbel%40gmail.com>,
    A Gretton
    <https://openreview.net/profile?email=arthur.gretton%40gmail.com>, W
    Li <https://openreview.net/profile?email=wcli%40math.ucla.edu>, G
    Montufar
    <https://openreview.net/profile?email=guidomontufar%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#Hklz71rYvS-details-747>
      o *TL;DR:* Estimator for the Wasserstein natural gradient
      o *Abstract:* Many machine learning problems can be expressed as the optimization of some cost functional over a parametric family of probability distributions. It is often beneficial to solve such optimization problems using natural gradient methods. These methods are invariant to the parametrization of the family, and thus can yield more effective optimization. Unfortunately, computing the natural gradient is challenging as it requires inverting a high dimensional matrix at each iteration. We propose a general framework to approximate the natural gradient for the Wasserstein metric, by leveraging a dual formulation of the metric restricted to a Reproducing Kernel Hilbert Space. Our approach leads to an estimator for gradient direction that can trade-off accuracy and computational cost, with theoretical guarantees. We verify its accuracy on simple examples, and show the advantage of using such an estimator in classification tasks on \texttt{Cifar10} and \texttt{Cifar100} empirically. 
      o *Keywords:* kernel methods, natural gradient, information geometry, Wasserstein metric
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Hklz71rYvS&name=original_pdf>
  *


            And the Bit Goes Down: Revisiting the Quantization of Neural
            Networks <https://openreview.net/forum?id=rJehVyrKwH>
            <https://openreview.net/pdf?id=rJehVyrKwH>

    Pierre Stock <https://openreview.net/profile?email=pstock%40fb.com>,
    Armand Joulin
    <https://openreview.net/profile?email=ajoulin%40fb.com>, Rémi
    Gribonval
    <https://openreview.net/profile?email=remi.gribonval%40inria.fr>,
    Benjamin Graham
    <https://openreview.net/profile?email=benjamingraham%40fb.com>,
    Hervé Jégou <https://openreview.net/profile?email=rvj%40fb.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 17 Replies
    Show details <#rJehVyrKwH-details-879>
      o *Keywords:* compression, quantization
      o *TL;DR:* Using a structured quantization technique aiming at better in-domain reconstruction to compress convolutional neural networks
      o *Abstract:* In this paper, we address the problem of reducing the memory footprint of convolutional network architectures. We introduce a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The principle of our approach is that it minimizes the loss reconstruction error for in-domain inputs. Our method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using byte-aligned codebooks to store the compressed weights. We validate our approach by quantizing a high performing ResNet-50 model to a memory size of 5MB (20x compression factor) while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.
      o *Code:* https://drive.google.com/file/d/12QK7onizf2ArpEBK706ly8bNfiM9cPzp/view?usp=sharing
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJehVyrKwH&name=original_pdf>
  *


            A Latent Morphology Model for Open-Vocabulary Neural Machine
            Translation <https://openreview.net/forum?id=BJxSI1SKDH>
            <https://openreview.net/pdf?id=BJxSI1SKDH>

    Duygu Ataman
    <https://openreview.net/profile?email=duyguataman%40gmail.com>,
    Wilker Aziz
    <https://openreview.net/profile?email=will.aziz%40gmail.com>,
    Alexandra Birch
    <https://openreview.net/profile?email=a.birch%40ed.ac.uk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 5 Replies
    Show details <#BJxSI1SKDH-details-414>
      o *Keywords:* neural machine translation, low-resource languages, latent-variable models
      o *Abstract:* Translation into morphologically-rich languages challenges neural machine translation (NMT) models with extremely sparse vocabularies where atomic treatment of surface forms is unrealistic. This problem is typically addressed by either pre-processing words into subword units or performing translation directly at the level of characters. The former is based on word segmentation algorithms optimized using corpus-level statistics with no regard to the translation task. The latter learns directly from translation data but requires rather deep architectures. In this paper, we propose to translate words by modeling word formation through a hierarchical latent variable model which mimics the process of morphological inflection. Our model generates words one character at a time by composing two latent representations: a continuous one, aimed at capturing the lexical semantics, and a set of (approximately) discrete features, aimed at capturing the morphosyntactic function, which are shared among different surface forms. Our model achieves better accuracy in translation into three morphologically-rich languages than conventional open-vocabulary NMT methods, while also demonstrating a better generalization capacity under low to mid-resource settings.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJxSI1SKDH&name=original_pdf>
  *


            Understanding Why Neural Networks Generalize Well Through
            GSNR of Parameters
            <https://openreview.net/forum?id=HyevIJStwH>
            <https://openreview.net/pdf?id=HyevIJStwH>

    Jinlong Liu
    <https://openreview.net/profile?email=ljlwykqh%40126.com>, Yunzhi
    Bai <https://openreview.net/profile?email=yunzhi.bai%40outlook.fr>,
    Guoqing Jiang
    <https://openreview.net/profile?email=jianggq%40pku.edu.cn>, Ting
    Chen <https://openreview.net/profile?email=roushi0322%40sina.cn>,
    Huayan Wang
    <https://openreview.net/profile?email=wanghuayan%40kuaishou.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#HyevIJStwH-details-807>
      o *Abstract:* As deep neural networks (DNNs) achieve tremendous success across many application domains, researchers tried to explore in many aspects on why they generalize well. In this paper, we provide a novel perspective on these issues using the gradient signal to noise ratio (GSNR) of parameters during training process of DNNs. The GSNR of a parameter is simply defined as the ratio between its gradient's squared mean and variance, over the data distribution. Based on several approximations, we establish a quantitative relationship between model parameters' GSNR and the generalization gap. This relationship indicates that larger GSNR during training process leads to better generalization performance. Futher, we show that, different from that of shallow models (e.g. logistic regression, support vector machines), the gradient descent optimization dynamics of DNNs naturally produces large GSNR during training, which is probably the key to DNNs’ remarkable generalization ability.
      o *Keywords:* DNN, generalization, GSNR, gradient descent
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HyevIJStwH&name=original_pdf>
  *


            Model Based Reinforcement Learning for Atari
            <https://openreview.net/forum?id=S1xCPJHtDB>
            <https://openreview.net/pdf?id=S1xCPJHtDB>

    Łukasz Kaiser
    <https://openreview.net/profile?email=lukaszkaiser%40google.com>,
    Mohammad Babaeizadeh
    <https://openreview.net/profile?email=mbz%40google.com>, Piotr Miłos
    <https://openreview.net/profile?email=pmilos%40mimuw.edu.pl>, Błażej
    Osiński
    <https://openreview.net/profile?email=blazej.osinski%40gmail.com>,
    Roy H Campbell
    <https://openreview.net/profile?email=rhc%40illinois.edu>, Konrad
    Czechowski
    <https://openreview.net/profile?email=konrad.czechowski%40gmail.com>, Dumitru
    Erhan <https://openreview.net/profile?email=dumitru%40google.com>,
    Chelsea Finn
    <https://openreview.net/profile?email=chelseaf%40google.com>, Piotr
    Kozakowski
    <https://openreview.net/profile?email=kozak000%40gmail.com>, Sergey
    Levine <https://openreview.net/profile?email=slevine%40google.com>,
    Afroz Mohiuddin
    <https://openreview.net/profile?email=afrozm%40google.com>, Ryan
    Sepassi
    <https://openreview.net/profile?email=rsepassi%40google.com>, George
    Tucker <https://openreview.net/profile?email=gjt%40google.com>,
    Henryk Michalewski
    <https://openreview.net/profile?email=henrykmichalewski%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#S1xCPJHtDB-details-613>
      o *TL;DR:* We use video prediction models, a model-based reinforcement learning algorithm and 2h of gameplay per game to train agents for 26 Atari games.
      o *Abstract:* Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.
      o *Code:* http://bit.ly/2wjgn1a
      o *Keywords:* reinforcement learning, model based rl, video prediction model, atari
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1xCPJHtDB&name=original_pdf>
  *


            Disagreement-Regularized Imitation Learning
            <https://openreview.net/forum?id=rkgbYyHtwB>
            <https://openreview.net/pdf?id=rkgbYyHtwB>

    Kiante Brantley
    <https://openreview.net/profile?email=kdbrant%40cs.umd.edu>, Wen Sun
    <https://openreview.net/profile?email=wen.sun%40microsoft.com>,
    Mikael Henaff
    <https://openreview.net/profile?email=mihenaff%40microsoft.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#rkgbYyHtwB-details-335>
      o *Keywords:* imitation learning, reinforcement learning, uncertainty
      o *TL;DR:* Method for addressing covariate shift in imitation learning using ensemble uncertainty
      o *Abstract:* We present a simple and effective algorithm designed to address the covariate shift problem in imitation learning. It operates by training an ensemble of policies on the expert demonstration data, and using the variance of their predictions as a cost which is minimized with RL together with a supervised behavioral cloning cost. Unlike adversarial imitation methods, it uses a fixed reward function which is easy to optimize. We prove a regret bound for the algorithm which is linear in the time horizon multiplied by a coefficient which we show to be low for certain problems in which behavioral cloning fails. We evaluate our algorithm empirically across multiple pixel-based Atari environments and continuous control tasks, and show that it matches or significantly outperforms behavioral cloning and generative adversarial imitation learning.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rkgbYyHtwB&name=original_pdf>
  *


            Stable Rank Normalization for Improved Generalization in
            Neural Networks and GANs
            <https://openreview.net/forum?id=H1enKkrFDB>
            <https://openreview.net/pdf?id=H1enKkrFDB>

    Amartya Sanyal
    <https://openreview.net/profile?email=amartya.sanyal%40cs.ox.ac.uk>,
    Philip H. Torr
    <https://openreview.net/profile?email=philip.torr%40eng.ox.ac.uk>,
    Puneet K. Dokania
    <https://openreview.net/profile?email=puneet%40robots.ox.ac.uk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 16 Replies
    Show details <#H1enKkrFDB-details-738>
      o *TL;DR:* We propose Stable Rank Normalisation, a new regularisor based on recent generelization bounds and show how to optimize it with extensive experiments.
      o *Abstract:* Exciting new work on generalization bounds for neural networks (NN) given by Bartlett et al. (2017); Neyshabur et al. (2018) closely depend on two parameter- dependant quantities: the Lipschitz constant upper bound and the stable rank (a softer version of rank). Even though these bounds typically have minimal practical utility, they facilitate questions on whether controlling such quantities together could improve the generalization behaviour of NNs in practice. To this end, we propose stable rank normalization (SRN), a novel, provably optimal, and computationally efficient weight-normalization scheme which minimizes the stable rank of a linear operator. Surprisingly we find that SRN, despite being non-convex, can be shown to have a unique optimal solution. We provide extensive analyses across a wide variety of NNs (DenseNet, WideResNet, ResNet, Alexnet, VGG), where applying SRN to their linear layers leads to improved classification accuracy, while simultaneously showing improvements in genealization, evaluated empirically using—(a) shattering experiments (Zhang et al., 2016); and (b) three measures of sample complexity by Bartlett et al. (2017), Neyshabur et al. (2018), & Wei & Ma. Additionally, we show that, when applied to the discriminator of GANs, it improves Inception, FID, and Neural divergence scores, while learning mappings with low empirical Lipschitz constant.
      o *Keywords:* Generelization, regularization, empirical lipschitz
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1enKkrFDB&name=original_pdf>
  *


            Measuring the Reliability of Reinforcement Learning
            Algorithms <https://openreview.net/forum?id=SJlpYJBKvH>
            <https://openreview.net/pdf?id=SJlpYJBKvH>

    Stephanie C.Y. Chan
    <https://openreview.net/profile?email=scychan%40google.com>, Samuel
    Fishman
    <https://openreview.net/profile?email=sfishman%40google.com>, Anoop
    Korattikara
    <https://openreview.net/profile?email=kbanoop%40google.com>, John
    Canny <https://openreview.net/profile?email=canny%40google.com>,
    Sergio Guadarrama
    <https://openreview.net/profile?email=sguada%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#SJlpYJBKvH-details-845>
      o *TL;DR:* A novel set of metrics for measuring reliability of reinforcement learning algorithms (+ accompanying statistical tests)
      o *Abstract:* Lack of reliability is a well-known issue for reinforcement learning (RL) algorithms. This problem has gained increasing attention in recent years, and efforts to improve it have grown substantially. To aid RL researchers and production users with the evaluation and improvement of reliability, we propose a set of metrics that quantitatively measure different aspects of reliability. In this work, we focus on variability and risk, both during training and after learning (on a fixed policy). We designed these metrics to be general-purpose, and we also designed complementary statistical tests to enable rigorous comparisons on these metrics. In this paper, we first describe the desired properties of the metrics and their design, the aspects of reliability that they measure, and their applicability to different scenarios. We then describe the statistical tests and make additional practical recommendations for reporting results. The metrics and accompanying statistical tools have been made available as an open-source library. We apply our metrics to a set of common RL algorithms and environments, compare them, and analyze the results.
      o *Keywords:* reinforcement learning, metrics, statistics, reliability
      o *Code:* https://github.com/google-research/rl-reliability-metrics
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SJlpYJBKvH&name=original_pdf>
  *


            Sequential Latent Knowledge Selection for Knowledge-Grounded
            Dialogue <https://openreview.net/forum?id=Hke0K1HKwr>
            <https://openreview.net/pdf?id=Hke0K1HKwr>

    Byeongchang Kim
    <https://openreview.net/profile?email=byeongchang.kim%40vision.snu.ac.kr>,
    Jaewoo Ahn
    <https://openreview.net/profile?email=jaewoo.ahn%40vision.snu.ac.kr>, Gunhee
    Kim <https://openreview.net/profile?email=gunhee%40snu.ac.kr>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#Hke0K1HKwr-details-180>
      o *TL;DR:* Our approach is the first attempt to leverage a sequential latent variable model for knowledge selection in the multi-turn knowledge-grounded dialogue. It achieves the new state-of-the-art performance on Wizard of Wikipedia benchmark.
      o *Abstract:* Knowledge-grounded dialogue is a task of generating an informative response based on both discourse context and external knowledge. As we focus on better modeling the knowledge selection in the multi-turn knowledge-grounded dialogue, we propose a sequential latent variable model as the first approach to this matter. The model named sequential knowledge transformer (SKT) can keep track of the prior and posterior distribution over knowledge; as a result, it can not only reduce the ambiguity caused from the diversity in knowledge selection of conversation but also better leverage the response information for proper choice of knowledge. Our experimental results show that the proposed model improves the knowledge selection accuracy and subsequently the performance of utterance generation. We achieve the new state-of-the-art performance on Wizard of Wikipedia (Dinan et al., 2019) as one of the most large-scale and challenging benchmarks. We further validate the effectiveness of our model over existing conversation methods in another knowledge-based dialogue Holl-E dataset (Moghe et al., 2018).
      o *Keywords:* dialogue, knowledge, language, conversation
      o *Code:* https://github.com/bckim92/sequential-knowledge-transformer
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Hke0K1HKwr&name=original_pdf>
  *


            Neural Tangents: Fast and Easy Infinite Neural Networks in
            Python <https://openreview.net/forum?id=SklD9yrFPS>
            <https://openreview.net/pdf?id=SklD9yrFPS>

    Roman Novak
    <https://openreview.net/profile?email=romann%40google.com>, Lechao
    Xiao <https://openreview.net/profile?email=xlc%40google.com>, Jiri
    Hron <https://openreview.net/profile?email=jh2084%40cam.ac.uk>,
    Jaehoon Lee
    <https://openreview.net/profile?email=jaehlee%40google.com>,
    Alexander A. Alemi
    <https://openreview.net/profile?email=alemi%40google.com>, Jascha
    Sohl-Dickstein
    <https://openreview.net/profile?email=jaschasd%40google.com>, Samuel
    S. Schoenholz
    <https://openreview.net/profile?email=schsam%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 16 Replies
    Show details <#SklD9yrFPS-details-745>
      o *TL;DR:* Keras for infinite neural networks.
      o *Abstract:* Neural Tangents is a library for working with infinite-width neural networks. It provides a high-level API for specifying complex and hierarchical neural network architectures. These networks can then be trained and evaluated either at finite-width as usual or in their infinite-width limit. Infinite-width networks can be trained analytically using exact Bayesian inference or using gradient descent via the Neural Tangent Kernel. Additionally, Neural Tangents provides tools to study gradient descent training dynamics of wide but finite networks in either function space or weight space.
              
              The entire library runs out-of-the-box on CPU, GPU, or TPU. All computations can be automatically distributed over multiple accelerators with near-linear scaling in the number of devices. 
              
              In addition to the repository below, we provide an accompanying interactive Colab notebook at
              https://colab.research.google.com/github/google/neural-tangents/blob/master/notebooks/neural_tangents_cookbook.ipynb
              
      o *Code:* https://www.github.com/google/neural-tangents
      o *Keywords:* Infinite Neural Networks, Gaussian Processes, Neural Tangent Kernel, NNGP, NTK, Software Library, Python, JAX
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SklD9yrFPS&name=original_pdf>
  *


            Self-labelling via simultaneous clustering and
            representation learning
            <https://openreview.net/forum?id=Hyx-jyBFPr>
            <https://openreview.net/pdf?id=Hyx-jyBFPr>

    Asano YM.
    <https://openreview.net/profile?email=yuki%40robots.ox.ac.uk>,
    Rupprecht C.
    <https://openreview.net/profile?email=chrisr%40robots.ox.ac.uk>,
    Vedaldi A.
    <https://openreview.net/profile?email=vedaldi%40robots.ox.ac.uk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 14 Replies
    Show details <#Hyx-jyBFPr-details-658>
      o *TL;DR:* We propose a self-supervised learning formulation that simultaneously learns feature representations and useful dataset labels by optimizing the common cross-entropy loss for features _and_ labels, while maximizing information.
      o *Abstract:* Combining clustering and representation learning is one of the most promising approaches for unsupervised learning of deep neural networks. However, doing so naively leads to ill posed learning problems with degenerate solutions.
              In this paper, we propose a novel and principled learning formulation that addresses these issues.
              The method is obtained by maximizing the information between labels and input data indices.
              We show that this criterion extends standard cross-entropy minimization to an optimal transport problem, which we solve efficiently for millions of input images and thousands of labels using a fast variant of the Sinkhorn-Knopp algorithm.
              The resulting method is able to self-label visual data so as to train highly competitive image representations without manual labels. Our method achieves state of the art representation learning performance for AlexNet and ResNet-50 on SVHN, CIFAR-10, CIFAR-100 and ImageNet and yields the first self-supervised AlexNet that outperforms the supervised Pascal VOC detection baseline. 
      o *Keywords:* self-supervision, feature representation learning, clustering
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Hyx-jyBFPr&name=original_pdf>
  *


            The intriguing role of module criticality in the
            generalization of deep networks
            <https://openreview.net/forum?id=S1e4jkSKvB>
            <https://openreview.net/pdf?id=S1e4jkSKvB>

    Niladri Chatterji
    <https://openreview.net/profile?email=niladri.chatterji%40berkeley.edu>,
    Behnam Neyshabur
    <https://openreview.net/profile?email=neyshabur%40google.com>, Hanie
    Sedghi <https://openreview.net/profile?email=hsedghi%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#S1e4jkSKvB-details-829>
      o *TL;DR:* We study the phenomenon that some modules of DNNs are more critical than others. Our analysis leads us to propose a complexity measure, that is able to explain the superior generalization performance of some architectures over others.
      o *Abstract:* We study the phenomenon that some modules of deep neural networks (DNNs) are more critical than others. Meaning that rewinding their parameter values back to initialization, while keeping other modules fixed at the trained parameters, results in a large drop in the network's performance. Our analysis reveals interesting properties of the loss landscape which leads us to propose a complexity measure, called module criticality, based on the shape of the valleys that connect the initial and final values of the module parameters. We formulate how generalization relates to the module criticality, and show that this measure is able to explain the superior generalization performance of some architectures over others, whereas, earlier measures fail to do so.
      o *Keywords:* Module Criticality Phenomenon, Complexity Measure, Deep Learning
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1e4jkSKvB&name=original_pdf>
  *


            Harnessing the Power of Infinitely Wide Deep Nets on
            Small-data Tasks
            <https://openreview.net/forum?id=rkl8sJBYvH>
            <https://openreview.net/pdf?id=rkl8sJBYvH>

    Sanjeev Arora
    <https://openreview.net/profile?email=arora%40cs.princeton.edu>,
    Simon S. Du <https://openreview.net/profile?email=ssdu%40ias.edu>,
    Zhiyuan Li
    <https://openreview.net/profile?email=zhiyuanli%40cs.princeton.edu>,
    Ruslan Salakhutdinov
    <https://openreview.net/profile?email=rsalakhu%40cs.cmu.edu>,
    Ruosong Wang
    <https://openreview.net/profile?email=ruosongw%40andrew.cmu.edu>,
    Dingli Yu
    <https://openreview.net/profile?email=dingliy%40cs.princeton.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#rkl8sJBYvH-details-336>
      o *TL;DR:* We verify neural tangent kernel is powerful on small data via experiments on UCI datasets, small CIFAR 10 and low-shot learning on VOC07.
      o *Abstract:* Recent research shows that the following two models are equivalent: (a) infinitely wide neural networks (NNs) trained under l2 loss by gradient descent with infinitesimally small learning rate (b) kernel regression with respect to so-called Neural Tangent Kernels (NTKs) (Jacot et al., 2018). An efficient algorithm to compute the NTK, as well as its convolutional counterparts, appears in Arora et al. (2019a), which allowed studying performance of infinitely wide nets on datasets like CIFAR-10. However, super-quadratic running time of kernel methods makes them best suited for small-data tasks. We report results suggesting neural tangent kernels perform strongly on low-data tasks.
              1. On a standard testbed of classification/regression tasks from the UCI database, NTK SVM beats the previous gold standard, Random Forests (RF), and also the corresponding finite nets.
              2. On CIFAR-10 with 10 – 640 training samples, Convolutional NTK consistently beats ResNet-34 by 1% - 3%.
              3. On VOC07 testbed for few-shot image classification tasks on ImageNet with transfer learning (Goyal et al., 2019), replacing the linear SVM currently used with a Convolutional NTK SVM consistently improves performance.
              4. Comparing the performance of NTK with the finite-width net it was derived from, NTK behavior starts at lower net widths than suggested by theoretical analysis(Arora et al., 2019a). NTK’s efficacy may trace to lower variance of output.
      o *Keywords:* small data, neural tangent kernel, UCI database, few-shot learning, kernel SVMs, deep learning theory, kernel design
      o *Code:* https://github.com/LeoYu/neural-tangent-kernel-UCI; https://drive.google.com/open?id=1SdgWmhEcnm4qyaM9xrkN01VF9tj40WZS
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rkl8sJBYvH&name=original_pdf>
  *


            Differentiation of Blackbox Combinatorial Solvers
            <https://openreview.net/forum?id=BkevoJSYPB>
            <https://openreview.net/pdf?id=BkevoJSYPB>

    Marin Vlastelica Pogančić
    <https://openreview.net/profile?email=marin.vlastelica%40tue.mpg.de>, Anselm
    Paulus
    <https://openreview.net/profile?email=anselm.paulus%40tuebingen.mpg.de>,
    Vit Musil
    <https://openreview.net/profile?email=vejtek%40atrey.karlin.mff.cuni.cz>,
    Georg Martius
    <https://openreview.net/profile?email=georg.martius%40tuebingen.mpg.de>,
    Michal Rolinek
    <https://openreview.net/profile?email=michal.rolinek%40tuebingen.mpg.de>

    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#BkevoJSYPB-details-56>
      o *TL;DR:*  In this work, we present a method that implements an efficient backward pass through blackbox implementations of combinatorial solvers with linear objective functions.
      o *Abstract:* Achieving fusion of deep learning with combinatorial algorithms promises transformative changes to artificial intelligence. One possible approach is to introduce combinatorial building blocks into neural networks. Such end-to-end architectures have the potential to tackle combinatorial problems on raw input data such as ensuring global consistency in multi-object tracking or route planning on maps in robotics. In this work, we present a method that implements an efficient backward pass through blackbox implementations of combinatorial solvers with linear objective functions. We provide both theoretical and experimental backing. In particular, we incorporate the Gurobi MIP solver, Blossom V algorithm, and Dijkstra's algorithm into architectures that extract suitable features from raw inputs for the traveling salesman problem, the min-cost perfect matching problem and the shortest path problem.
      o *Code:* https://sites.google.com/view/combinatorialgradients/home
      o *Keywords:* combinatorial algorithms, deep learning, representation learning, optimization
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BkevoJSYPB&name=original_pdf>
  *


            Scaling Autoregressive Video Models
            <https://openreview.net/forum?id=rJgsskrFwH>
            <https://openreview.net/pdf?id=rJgsskrFwH>

    Dirk Weissenborn
    <https://openreview.net/profile?email=diwe%40google.com>, Oscar
    Täckström
    <https://openreview.net/profile?email=oscar.tackstrom%40gmail.com>,
    Jakob Uszkoreit <https://openreview.net/profile?email=usz%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#rJgsskrFwH-details-202>
      o *Keywords:* autoregressive models, video prediction, generative models, video generation
      o *TL;DR:* We present a novel autoregressive video generation that achieves strong results on popular datasets and produces encouraging continuations of real world videos.
      o *Abstract:* Due to the statistical complexity of video, the high degree of inherent stochasticity, and the sheer amount of data, generating natural video remains a challenging task. State-of-the-art video generation models attempt to address these issues by combining sometimes complex, often video-specific neural network architectures, latent variable models, adversarial training and a range of other methods. Despite their often high complexity, these approaches still fall short of generating high quality video continuations outside of narrow domains and often struggle with fidelity. In contrast, we show that conceptually simple, autoregressive video generation models based on a three-dimensional self-attention mechanism achieve highly competitive results across multiple metrics on popular benchmark datasets for which they produce continuations of high fidelity and realism. Furthermore, we find that our models are capable of producing diverse and surprisingly realistic continuations on a subset of videos from Kinetics, a large scale action recognition dataset comprised of YouTube videos exhibiting phenomena such as camera movement, complex object interactions and diverse human movement. To our knowledge, this is the first promising application of video-generation models to videos of this complexity.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJgsskrFwH&name=original_pdf>
  *


            The Ingredients of Real World Robotic Reinforcement Learning
            <https://openreview.net/forum?id=rJe2syrtvS>
            <https://openreview.net/pdf?id=rJe2syrtvS>

    Henry Zhu
    <https://openreview.net/profile?email=henryzhu%40berkeley.edu>,
    Justin Yu
    <https://openreview.net/profile?email=justinvyu%40berkeley.edu>,
    Abhishek Gupta
    <https://openreview.net/profile?email=abhigupta%40berkeley.edu>,
    Dhruv Shah
    <https://openreview.net/profile?email=shah%40eecs.berkeley.edu>,
    Kristian Hartikainen
    <https://openreview.net/profile?email=kristian.hartikainen%40gmail.com>,
    Avi Singh
    <https://openreview.net/profile?email=avisingh%40cs.berkeley.edu>,
    Vikash Kumar
    <https://openreview.net/profile?email=vikashplus%40gmail.com>,
    Sergey Levine
    <https://openreview.net/profile?email=svlevine%40eecs.berkeley.edu>
    25 Sep 2019 (modified: 26 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#rJe2syrtvS-details-336>
      o *TL;DR:* System to learn robotic tasks in the real world with reinforcement learning without instrumentation
      o *Abstract:* The success of reinforcement learning in the real world has been limited to instrumented laboratory scenarios, often requiring arduous human supervision to enable continuous learning. In this work, we discuss the required elements of a robotic system that can continually and autonomously improve with data collected in the real world, and propose a particular instantiation of such a system. Subsequently, we investigate a number of challenges of learning without instrumentation -- including the lack of episodic resets, state estimation, and hand-engineered rewards -- and propose simple, scalable solutions to these challenges. We demonstrate the efficacy of our proposed system on dexterous robotic manipulation tasks in simulation and the real world, and also provide an insightful analysis and ablation study of the challenges associated with this learning paradigm.
      o *Keywords:* Reinforcement Learning, Robotics
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJe2syrtvS&name=original_pdf>
  *


            Meta-Learning Acquisition Functions for Transfer Learning in
            Bayesian Optimization
            <https://openreview.net/forum?id=ryeYpJSKwr>
            <https://openreview.net/pdf?id=ryeYpJSKwr>

    Michael Volpp
    <https://openreview.net/profile?email=mvolpp89%40googlemail.com>,
    Lukas P. Fröhlich
    <https://openreview.net/profile?email=lukas.froehlich%40de.bosch.com>,
    Kirsten Fischer
    <https://openreview.net/profile?email=k.fischer-lotte%40online.de>,
    Andreas Doerr
    <https://openreview.net/profile?email=andreas.doerr3%40de.bosch.com>, Stefan
    Falkner
    <https://openreview.net/profile?email=stefan.falkner%40de.bosch.com>, Frank
    Hutter
    <https://openreview.net/profile?email=fh%40cs.uni-freiburg.de>,
    Christian Daniel
    <https://openreview.net/profile?email=christian.daniel%40de.bosch.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#ryeYpJSKwr-details-918>
      o *TL;DR:* We perform efficient and flexible transfer learning in the framework of Bayesian optimization through meta-learned neural acquisition functions.
      o *Abstract:* Transferring knowledge across tasks to improve data-efficiency is one of the open key challenges in the field of global black-box optimization. Readily available algorithms are typically designed to be universal optimizers and, therefore, often suboptimal for specific tasks. We propose a novel transfer learning method to obtain customized optimizers within the well-established framework of Bayesian optimization, allowing our algorithm to utilize the proven generalization capabilities of Gaussian processes. Using reinforcement learning to meta-train an acquisition function (AF) on a set of related tasks, the proposed method learns to extract implicit structural information and to exploit it for improved data-efficiency. We present experiments on a simulation-to-real transfer task as well as on several synthetic functions and on two hyperparameter search problems. The results show that our algorithm (1) automatically identifies structural properties of objective functions from available source tasks or simulations, (2) performs favourably in settings with both scarse and abundant source data, and (3) falls back to the performance level of general AFs if no particular structure is present.
      o *Code:* https://github.com/metabo-iclr2020/MetaBO
      o *Keywords:* Transfer Learning, Meta Learning, Bayesian Optimization, Reinforcement Learning
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=ryeYpJSKwr&name=original_pdf>
  *


            Maximum Likelihood Constraint Inference for Inverse
            Reinforcement Learning
            <https://openreview.net/forum?id=BJliakStvH>
            <https://openreview.net/pdf?id=BJliakStvH>

    Dexter R.R. Scobee
    <https://openreview.net/profile?email=dscobee%40eecs.berkeley.edu>,
    S. Shankar Sastry
    <https://openreview.net/profile?email=sastry%40eecs.berkeley.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#BJliakStvH-details-296>
      o *TL;DR:* Our method infers constraints on task execution by leveraging the principle of maximum entropy to quantify how demonstrations differ from expected, un-constrained behavior.
      o *Abstract:* While most approaches to the problem of Inverse Reinforcement Learning (IRL) focus on estimating a reward function that best explains an expert agent’s policy or demonstrated behavior on a control task, it is often the case that such behavior is more succinctly represented by a simple reward combined with a set of hard constraints. In this setting, the agent is attempting to maximize cumulative rewards subject to these given constraints on their behavior. We reformulate the problem of IRL on Markov Decision Processes (MDPs) such that, given a nominal model of the environment and a nominal reward function, we seek to estimate state, action, and feature constraints in the environment that motivate an agent’s behavior. Our approach is based on the Maximum Entropy IRL framework, which allows us to reason about the likelihood of an expert agent’s demonstrations given our knowledge of an MDP. Using our method, we can infer which constraints can be added to the MDP to most increase the likelihood of observing these demonstrations. We present an algorithm which iteratively infers the Maximum Likelihood Constraint to best explain observed behavior, and we evaluate its efficacy using both simulated behavior and recorded data of humans navigating around an obstacle.
      o *Code:* https://drive.google.com/drive/folders/1h2J7o4w4J0_dpldTRpFu_jWQR8CkBbXw
      o *Keywords:* learning from demonstration, inverse reinforcement learning, constraint inference
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJliakStvH&name=original_pdf>
  *


            Spectral Embedding of Regularized Block Models
            <https://openreview.net/forum?id=H1l_0JBYwS>
            <https://openreview.net/pdf?id=H1l_0JBYwS>

    Nathan De Lara
    <https://openreview.net/profile?email=ndelara%40enst.fr>, Thomas
    Bonald <https://openreview.net/profile?email=bonald%40enst.fr>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 4 Replies
    Show details <#H1l_0JBYwS-details-408>
      o *TL;DR:* Graph regularization forces spectral embedding to focus on the largest clusters, making the representation less sensitive to noise. 
      o *Abstract:* Spectral embedding is a popular technique for the representation of graph data. Several regularization techniques have been proposed to improve the quality of the embedding with respect to downstream tasks like clustering. In this paper, we explain on a simple block model the impact of the complete graph regularization, whereby a constant is added to all entries of the adjacency matrix. Specifically, we show that the regularization forces the spectral embedding  to focus on  the  largest blocks, making the representation less sensitive to noise or outliers. We illustrate these results on both  on both synthetic and real data, showing how regularization improves standard clustering scores. 
      o *Code:* https://github.com/nathandelara/Spectral-Embedding-of-Regularized-Block-Models/
      o *Keywords:* Spectral embedding, regularization, block models, clustering
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1l_0JBYwS&name=original_pdf>
  *


            Towards Hierarchical Importance Attribution: Explaining
            Compositional Semantics for Neural Sequence Models
            <https://openreview.net/forum?id=BkxRRkSKwr>
            <https://openreview.net/pdf?id=BkxRRkSKwr>

    Xisen Jin <https://openreview.net/profile?email=xisenjin%40usc.edu>,
    Zhongyu Wei
    <https://openreview.net/profile?email=zywei%40fudan.edu.cn>, Junyi
    Du <https://openreview.net/profile?email=junyidu%40usc.edu>,
    Xiangyang Xue
    <https://openreview.net/profile?email=xyxue%40fudan.edu.cn>, Xiang
    Ren <https://openreview.net/profile?email=xiangren%40usc.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 11 Replies
    Show details <#BkxRRkSKwr-details-3>
      o *TL;DR:* We propose measurement of phrase importance and algorithms for hierarchical explanation of neural sequence model predictions
      o *Abstract:* The impressive performance of neural networks on natural language processing tasks attributes to their ability to model complicated word and phrase compositions. To explain how the model handles semantic compositions, we study hierarchical explanation of neural network predictions. We identify non-additivity and context independent importance attributions within hierarchies as two desirable properties for highlighting word and phrase compositions. We show some prior efforts on hierarchical explanations, e.g. contextual decomposition, do not satisfy the desired properties mathematically, leading to inconsistent explanation quality in different models. In this paper, we start by proposing a formal and general way to quantify the importance of each word and phrase. Following the formulation, we propose Sampling and Contextual Decomposition (SCD) algorithm and Sampling and Occlusion (SOC) algorithm. Human and metrics evaluation on both LSTM models and BERT Transformer models on multiple datasets show that our algorithms outperform prior hierarchical explanation algorithms. Our algorithms help to visualize semantic composition captured by models, extract classification rules and improve human trust of models.
      o *Keywords:* natural language processing, interpretability
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BkxRRkSKwr&name=original_pdf>
  *


            word2ket: Space-efficient Word Embeddings inspired by
            Quantum Entanglement
            <https://openreview.net/forum?id=HkxARkrFwB>
            <https://openreview.net/pdf?id=HkxARkrFwB>

    Aliakbar Panahi
    <https://openreview.net/profile?email=panahia%40vcu.edu>, Seyran
    Saeedi <https://openreview.net/profile?email=saeedis%40vcu.edu>, Tom
    Arodz <https://openreview.net/profile?email=tarodz%40vcu.edu>
    25 Sep 2019 (modified: 24 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#HkxARkrFwB-details-790>
      o *TL;DR:* We use ideas from quantum computing to propose word embeddings that utilize much fewer trainable parameters.
      o *Abstract:* Deep learning natural language processing models often use vector word embeddings, such as word2vec or GloVe, to represent words. A discrete sequence of words can be much more easily integrated with downstream neural layers if it is represented as a  sequence of continuous vectors. Also, semantic relationships between words, learned from a text corpus, can be encoded in the relative configurations of the embedding vectors. However, storing and accessing embedding vectors for all words in a dictionary requires large amount of space, and may stain systems with limited GPU memory. Here, we used approaches inspired by quantum computing to propose two related methods, word2ket and word2ketXS, for storing word embedding matrix during training and inference in a highly efficient way. Our approach achieves a hundred-fold or more reduction in the space required to store the embeddings with almost no relative drop in accuracy in practical natural language processing tasks.
      o *Keywords:* word embeddings, natural language processing, model reduction
      o *Code:* https://github.com/panaali/word2ket
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HkxARkrFwB&name=original_pdf>
  *


            What Can Neural Networks Reason About?
            <https://openreview.net/forum?id=rJxbJeHFPS>
            <https://openreview.net/pdf?id=rJxbJeHFPS>

    Keyulu Xu <https://openreview.net/profile?email=keyulu%40mit.edu>,
    Jingling Li
    <https://openreview.net/profile?email=jingling%40cs.umd.edu>, Mozhi
    Zhang <https://openreview.net/profile?email=mozhi%40cs.umd.edu>,
    Simon S. Du <https://openreview.net/profile?email=ssdu%40ias.edu>,
    Ken-ichi Kawarabayashi
    <https://openreview.net/profile?email=k_keniti%40nii.ac.jp>,
    Stefanie Jegelka
    <https://openreview.net/profile?email=stefje%40mit.edu>
    25 Sep 2019 (modified: 27 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 16 Replies
    Show details <#rJxbJeHFPS-details-339>
      o *TL;DR:* We develop a theoretical framework to characterize what a neural network can learn to reason about.
      o *Abstract:* Neural networks have succeeded in many reasoning tasks. Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, but less structured networks fail. Theoretically, there is limited understanding of why and when a network structure generalizes better than others, although they have equal expressive power. In this paper, we develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. We formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. As an example, we unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP). We show that GNNs align with DP and thus are expected to solve these tasks. On several reasoning tasks, our theory is supported by empirical results.
      o *Keywords:* reasoning, deep learning theory, algorithmic alignment, graph neural networks
      o *Code:* https://github.com/NNReasoning/What-Can-Neural-Networks-Reason-About 
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJxbJeHFPS&name=original_pdf>
  *


            Training individually fair ML models with sensitive subspace
            robustness <https://openreview.net/forum?id=B1gdkxHFDH>
            <https://openreview.net/pdf?id=B1gdkxHFDH>

    Mikhail Yurochkin
    <https://openreview.net/profile?email=mikhail.yurochkin%40ibm.com>,
    Amanda Bower
    <https://openreview.net/profile?email=amandarg%40umich.edu>, Yuekai
    Sun <https://openreview.net/profile?email=yuekai%40umich.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 8 Replies
    Show details <#B1gdkxHFDH-details-295>
      o *Keywords:* fairness, adversarial robustness
      o *TL;DR:* Algorithm for training individually fair classifier using adversarial robustness
      o *Abstract:* We consider training machine learning models that are fair in the sense that their performance is invariant under certain sensitive perturbations to the inputs. For example, the performance of a resume screening system should be invariant under changes to the gender and/or ethnicity of the applicant. We formalize this notion of algorithmic fairness as a variant of individual fairness and develop a distributionally robust optimization approach to enforce it during training. We also demonstrate the effectiveness of the approach on two ML tasks that are susceptible to gender and racial biases. 
      o *Code:* https://github.com/IBM/sensitive-subspace-robustness
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1gdkxHFDH&name=original_pdf>
  *


            Learning from Rules Generalizing Labeled Exemplars
            <https://openreview.net/forum?id=SkeuexBtDr>
            <https://openreview.net/pdf?id=SkeuexBtDr>

    Abhijeet Awasthi
    <https://openreview.net/profile?email=awasthi%40cse.iitb.ac.in>,
    Sabyasachi Ghosh
    <https://openreview.net/profile?email=sghosh%40cse.iitb.ac.in>,
    Rasna Goyal
    <https://openreview.net/profile?email=rasna.goyal66%40gmail.com>,
    Sunita Sarawagi
    <https://openreview.net/profile?email=sunita%40iitb.ac.in>
    25 Sep 2019 (modified: 22 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#SkeuexBtDr-details-643>
      o *TL;DR:* Coupled rule-exemplar supervision and a implication loss helps to jointly learn to denoise rules and imply labels.
      o *Abstract:* In many applications labeled data is not readily available, and needs to be collected via pain-staking human supervision. We propose a rule-exemplar method for collecting human supervision to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. We propose a training algorithm that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that (1) our algorithm is more accurate than several existing methods of learning from a mix of clean and noisy supervision, and (2) the coupled rule-exemplar supervision is effective in denoising rules.
      o *Keywords:* Learning from Rules, Learning from limited labeled data, Weakly Supervised Learning
      o *Code:* https://github.com/awasthiabhijeet/Learning-From-Rules
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SkeuexBtDr&name=original_pdf>
  *


            Directional Message Passing for Molecular Graphs
            <https://openreview.net/forum?id=B1eWbxStPH>
            <https://openreview.net/pdf?id=B1eWbxStPH>

    Johannes Klicpera
    <https://openreview.net/profile?email=klicpera%40in.tum.de>, Janek
    Groß <https://openreview.net/profile?email=grossja%40in.tum.de>,
    Stephan Günnemann
    <https://openreview.net/profile?email=guennemann%40in.tum.de>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#B1eWbxStPH-details-271>
      o *TL;DR:* Directional message passing incorporates spatial directional information to improve graph neural networks.
      o *Abstract:* Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1/4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76% on MD17 and by 31% on QM9. Our implementation is available online.
      o *Code:* https://www.daml.in.tum.de/dimenet
      o *Keywords:* GNN, Graph neural network, message passing, graphs, equivariance, molecules
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1eWbxStPH&name=original_pdf>
  *


            Explanation by Progressive Exaggeration
            <https://openreview.net/forum?id=H1xFWgrFPS>
            <https://openreview.net/pdf?id=H1xFWgrFPS>

    Sumedha Singla
    <https://openreview.net/profile?email=sumedha.singla%40pitt.edu>,
    Brian Pollack
    <https://openreview.net/profile?email=kayhan%40pitt.edu>, Junxiang
    Chen <https://openreview.net/profile?email=cjx880409%40gmail.com>,
    Kayhan Batmanghelich
    <https://openreview.net/profile?email=kayhan%40pitt.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#H1xFWgrFPS-details-97>
      o *TL;DR:* A method to explain a classifier, by generating visual perturbation of an image by exaggerating  or diminishing the semantic features that the classifier associates with a target label.
      o *Abstract:* As machine learning methods see greater adoption and implementation in high stakes applications such as medical image diagnosis, the need for model interpretability and explanation has become more critical. Classical approaches that assess feature importance (eg saliency maps) do not explain how and why a particular region of an image is relevant to the prediction. We propose a method that explains the outcome of a classification black-box by gradually exaggerating the semantic effect of a given class. Given a query input to a classifier, our method produces a progressive set of plausible variations of that query, which gradually change the posterior probability from its original class to its negation. These counter-factually generated samples preserve features unrelated to the classification decision, such that a user can employ our method as a ``tuning knob'' to traverse a data manifold while crossing the decision boundary.  Our method is model agnostic and only requires the output value and gradient of the predictor with respect to its input.
      o *Keywords:* Explain, deep learning, black box, GAN, counterfactual
      o *Code:* https://github.com/batmanlab/Explanation_by_Progressive_Exaggeration.git
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1xFWgrFPS&name=original_pdf>
  *


            Compression based bound for non-compressed network: unified
            generalization error analysis of large compressible deep
            neural network <https://openreview.net/forum?id=ByeGzlrKwH>
            <https://openreview.net/pdf?id=ByeGzlrKwH>

    Taiji Suzuki
    <https://openreview.net/profile?email=taiji%40mist.i.u-tokyo.ac.jp>,
    Hiroshi Abe
    <https://openreview.net/profile?email=abe%40ipride.co.jp>, Tomoaki
    Nishimura
    <https://openreview.net/profile?email=tomoaki.nishimura%40nttdata.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#ByeGzlrKwH-details-558>
      o *Abstract:* One of the biggest issues in deep learning theory is the generalization ability of networks with huge model size. 
              The classical learning theory suggests that overparameterized models cause overfitting.
              However, practically used large deep models avoid overfitting, which is not well explained by the classical approaches.
              To resolve this issue, several attempts have been made. 
              Among them, the compression based bound is one of the promising approaches. 
              However, the compression based bound can be applied only to a compressed network, and it is not applicable to the non-compressed original network. 
              In this paper, we give a unified frame-work that can convert compression based bounds to those for non-compressed original networks.
              The bound gives even better rate than the one for the compressed network by improving the bias term.
              By establishing the unified frame-work, we can obtain a data dependent generalization error bound which gives a tighter evaluation than the data independent ones.
              
      o *Keywords:* Generalization error, compression based bound, local Rademacher complexity
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=ByeGzlrKwH&name=original_pdf>
  *


            At Stability's Edge: How to Adjust Hyperparameters to
            Preserve Minima Selection in Asynchronous Training of Neural
            Networks? <https://openreview.net/forum?id=Bkeb7lHtvH>
            <https://openreview.net/pdf?id=Bkeb7lHtvH>

    Niv Giladi
    <https://openreview.net/profile?email=giladiniv%40gmail.com>, Mor
    Shpigel Nacson
    <https://openreview.net/profile?email=mor.shpigel%40gmail.com>, Elad
    Hoffer
    <https://openreview.net/profile?email=elad.hoffer%40gmail.com>,
    Daniel Soudry
    <https://openreview.net/profile?email=daniel.soudry%40gmail.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#Bkeb7lHtvH-details-643>
      o *Keywords:* implicit bias, stability, neural networks, generalization gap, asynchronous SGD
      o *TL;DR:* How to prevent stale gradients (in asynchronous SGD) from changing minima stability and degrade steady state generalization?
      o *Abstract:* Background: Recent developments have made it possible to accelerate neural networks training significantly using large batch sizes and data parallelism. Training in an asynchronous fashion, where delay occurs, can make training even more scalable. However, asynchronous training has its pitfalls, mainly a degradation in generalization, even after convergence of the algorithm. This gap remains not well understood, as theoretical analysis so far mainly focused on the convergence rate of asynchronous methods.
              Contributions: We examine asynchronous training from the perspective of dynamical stability. We find that the degree of delay interacts with the learning rate, to change the set of minima accessible by an asynchronous stochastic gradient descent algorithm. We derive closed-form rules on how the learning rate could be changed, while keeping the accessible set the same. Specifically, for high delay values, we find that the learning rate should be kept inversely proportional to the delay. We then extend this analysis to include momentum. We find momentum should be either turned off, or modified to improve training stability.  We provide empirical experiments to validate our theoretical findings.
      o *Code:* https://github.com/paper-submissions/delay_stability
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Bkeb7lHtvH&name=original_pdf>
  *


            Disentanglement by Nonlinear ICA with General
            Incompressible-flow Networks (GIN)
            <https://openreview.net/forum?id=rygeHgSFDH>
            <https://openreview.net/pdf?id=rygeHgSFDH>

    Peter Sorrenson
    <https://openreview.net/profile?email=peter.sorrenson%40gmail.com>,
    Carsten Rother
    <https://openreview.net/profile?email=carsten.rother%40iwr.uni-heidelberg.de>,
    Ullrich Köthe
    <https://openreview.net/profile?email=ullrich.koethe%40iwr.uni-heidelberg.de>

    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#rygeHgSFDH-details-925>
      o *Abstract:* A central question of representation learning asks under which conditions it is possible to reconstruct the true latent variables of an arbitrarily complex generative process. Recent breakthrough work by Khemakhem et al. (2019) on nonlinear ICA has answered this question for a broad class of conditional generative processes. We extend this important result in a direction relevant for application to real-world data. First, we generalize the theory to the case of unknown intrinsic problem dimension and prove that in some special (but not very restrictive) cases, informative latent variables will be automatically separated from noise by an estimating model. Furthermore, the recovered informative latent variables will be in one-to-one correspondence with the true latent variables of the generating process, up to a trivial component-wise transformation. Second, we introduce a modification of the RealNVP invertible neural network architecture (Dinh et al. (2016)) which is particularly suitable for this type of problem: the General Incompressible-flow Network (GIN). Experiments on artificial data and EMNIST demonstrate that theoretical predictions are indeed verified in practice. In particular, we provide a detailed set of exactly 22 informative latent variables extracted from EMNIST.
      o *Keywords:* disentanglement, nonlinear ICA, representation learning, feature discovery, theoretical justification
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rygeHgSFDH&name=original_pdf>
  *


            Kaleidoscope: An Efficient, Learnable Representation For All
            Structured Linear Maps
            <https://openreview.net/forum?id=BkgrBgSYDS>
            <https://openreview.net/pdf?id=BkgrBgSYDS>

    Tri Dao <https://openreview.net/profile?email=trid%40stanford.edu>,
    Nimit Sohoni
    <https://openreview.net/profile?email=nims%40stanford.edu>, Albert
    Gu <https://openreview.net/profile?email=albertgu%40stanford.edu>,
    Matthew Eichhorn
    <https://openreview.net/profile?email=mae226%40cornell.edu>, Amit
    Blonder
    <https://openreview.net/profile?email=amitblon%40buffalo.edu>, Megan
    Leszczynski
    <https://openreview.net/profile?email=mleszczy%40stanford.edu>, Atri
    Rudra <https://openreview.net/profile?email=atri%40buffalo.edu>,
    Christopher Ré
    <https://openreview.net/profile?email=chrismre%40cs.stanford.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#BkgrBgSYDS-details-688>
      o *TL;DR:* We propose a differentiable family of "kaleidoscope matrices," prove that all structured matrices can be represented in this form, and use them to replace hand-crafted linear maps in deep learning models.
      o *Abstract:* Modern neural network architectures use structured linear transformations, such as low-rank matrices, sparse matrices, permutations, and the Fourier transform, to improve inference speed and reduce memory usage compared to general linear maps. However, choosing which of the myriad structured transformations to use (and its associated parameterization) is a laborious task that requires trading off speed, space, and accuracy. We consider a different approach: we introduce a family of matrices called kaleidoscope matrices (K-matrices) that provably capture any structured matrix with near-optimal space (parameter) and time (arithmetic operation) complexity. We empirically validate that K-matrices can be automatically learned within end-to-end pipelines to replace hand-crafted procedures, in order to improve model quality. For example, replacing channel shuffles in ShuffleNet improves classification accuracy on ImageNet by up to 5%. K-matrices can also simplify hand-engineered pipelines---we replace filter bank feature computation in speech data preprocessing with a learnable kaleidoscope layer, resulting in only 0.4% loss in accuracy on the TIMIT speech recognition task. In addition, K-matrices can capture latent structure in models: for a challenging permuted image classification task, adding a K-matrix to a standard convolutional architecture can enable learning the latent permutation and improve accuracy by over 8 points. We provide a practically efficient implementation of our approach, and use K-matrices in a Transformer network to attain 36% faster end-to-end inference speed on a language translation task.
      o *Code:* https://github.com/HazyResearch/learning-circuits
      o *Keywords:* structured matrices, efficient ML, algorithms, butterfly matrices, arithmetic circuits
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BkgrBgSYDS&name=original_pdf>
  *


            Improving Generalization in Meta Reinforcement Learning
            using Learned Objectives
            <https://openreview.net/forum?id=S1evHerYPr>
            <https://openreview.net/pdf?id=S1evHerYPr>

    Louis Kirsch
    <https://openreview.net/profile?email=louis%40idsia.ch>, Sjoerd van
    Steenkiste <https://openreview.net/profile?email=sjoerd%40idsia.ch>,
    Juergen Schmidhuber
    <https://openreview.net/profile?email=juergen%40idsia.ch>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#S1evHerYPr-details-371>
      o *TL;DR:* We introduce MetaGenRL, a novel meta reinforcement learning algorithm. Unlike prior work, MetaGenRL can generalize to new environments that are entirely different from those used for meta-training.
      o *Abstract:* Biological evolution has distilled the experiences of many learners into the general learning algorithms of humans. Our novel meta reinforcement learning algorithm MetaGenRL is inspired by this process. MetaGenRL distills the experiences of many complex agents to meta-learn a low-complexity neural objective function that decides how future individuals will learn. Unlike recent meta-RL algorithms, MetaGenRL can generalize to new environments that are entirely different from those used for meta-training. In some cases, it even outperforms human-engineered RL algorithms. MetaGenRL uses off-policy second-order gradients during meta-training that greatly increase its sample efficiency.
      o *Keywords:* meta reinforcement learning, meta learning, reinforcement learning
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1evHerYPr&name=original_pdf>
  *


            Drawing Early-Bird Tickets: Toward More Efficient Training
            of Deep Networks
            <https://openreview.net/forum?id=BJxsrgStvr>
            <https://openreview.net/pdf?id=BJxsrgStvr>

    Haoran You <https://openreview.net/profile?email=hy34%40rice.edu>,
    Chaojian Li <https://openreview.net/profile?email=cl114%40rice.edu>,
    Pengfei Xu <https://openreview.net/profile?email=px5%40rice.edu>,
    Yonggan Fu <https://openreview.net/profile?email=yf22%40rice.edu>,
    Yue Wang <https://openreview.net/profile?email=yw68%40rice.edu>,
    Xiaohan Chen
    <https://openreview.net/profile?email=chernxh%40tamu.edu>, Richard
    G. Baraniuk <https://openreview.net/profile?email=richb%40rice.edu>,
    Zhangyang Wang
    <https://openreview.net/profile?email=atlaswang%40tamu.edu>, Yingyan
    Lin <https://openreview.net/profile?email=yingyan.lin%40rice.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#BJxsrgStvr-details-331>
      o *Abstract:* (Frankle & Carbin, 2019) shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve comparable accuracies to the latter in a similar number of iterations. However, the identification of these winning tickets still requires the costly train-prune-retrain process, limiting their practical benefits. In this paper, we discover for the first time that the winning tickets can be identified at the very early training stage, which we term as Early-Bird (EB) tickets, via low-cost training schemes (e.g., early stopping and low-precision training) at large learning rates. Our finding of EB tickets is consistent with recently reported observations that the key connectivity patterns of neural networks emerge early. Furthermore, we propose a mask distance metric that can be used to identify EB tickets with low computational overhead, without needing to know the true winning tickets that emerge after the full training. Finally, we leverage the existence of EB tickets and the proposed mask distance to develop efficient training methods, which are achieved by first identifying EB tickets via low-cost schemes, and then continuing to train merely the EB tickets towards the target accuracy. Experiments based on various deep networks and datasets validate: 1) the existence of EB tickets, and the effectiveness of mask distance in efficiently identifying them; and 2) that the proposed efficient training via EB tickets can achieve up to 4.7x energy savings while maintaining comparable or even better accuracy, demonstrating a promising and easily adopted method for tackling cost-prohibitive deep network training.
      o *Code:* https://github.com/RICE-EIC/Early-Bird-Tickets
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJxsrgStvr&name=original_pdf>
  *


            Truth or backpropaganda? An empirical investigation of deep
            learning theory <https://openreview.net/forum?id=HyxyIgHFvr>
            <https://openreview.net/pdf?id=HyxyIgHFvr>

    Micah Goldblum
    <https://openreview.net/profile?email=goldblumcello%40gmail.com>,
    Jonas Geiping
    <https://openreview.net/profile?email=jonas.geiping%40uni-siegen.de>, Avi
    Schwarzschild <https://openreview.net/profile?email=avi1%40umd.edu>,
    Michael Moeller
    <https://openreview.net/profile?email=michael.moeller%40uni-siegen.de>,
    Tom Goldstein <https://openreview.net/profile?email=tomg%40cs.umd.edu>
    25 Sep 2019 (modified: 27 Apr 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 15 Replies
    Show details <#HyxyIgHFvr-details-912>
      o *Abstract:* We empirically evaluate common assumptions about neural networks that are widely held by practitioners and theorists alike.  In this work, we: (1) prove the widespread existence of suboptimal local minima in the loss landscape of neural networks, and we use our theory to find examples; (2) show that small-norm parameters are not optimal for generalization; (3) demonstrate that ResNets do not conform to wide-network theories, such as the neural tangent kernel, and that the interaction between skip connections and batch normalization plays a role;  (4) find that rank does not correlate with generalization or robustness in a practical setting.
      o *Keywords:* Deep learning, generalization, loss landscape, robustness
      o *TL;DR:* We call into question commonly held beliefs regarding the loss landscape, optimization, network width, and rank.
      o *Code:* https://github.com/goldblum/TruthOrBackpropaganda
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=HyxyIgHFvr&name=original_pdf>
  *


            Neural Arithmetic Units
            <https://openreview.net/forum?id=H1gNOeHKPS>
            <https://openreview.net/pdf?id=H1gNOeHKPS>

    Andreas Madsen
    <https://openreview.net/profile?email=amwebdk%40gmail.com>,
    Alexander Rosenberg Johansen
    <https://openreview.net/profile?email=alexander%40herhjemme.dk>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 16 Replies
    Show details <#H1gNOeHKPS-details-121>
      o *Abstract:* Neural networks can approximate complex functions, but they struggle to perform exact arithmetic operations over real numbers. The lack of inductive bias for arithmetic operations leaves neural networks without the underlying logic necessary to extrapolate on tasks such as addition, subtraction, and multiplication. We present two new neural network components: the Neural Addition Unit (NAU), which can learn exact addition and subtraction; and the Neural Multiplication Unit (NMU) that can multiply subsets of a vector. The NMU is, to our knowledge, the first arithmetic neural network component that can learn to multiply elements from a vector, when the hidden size is large. The two new components draw inspiration from a theoretical analysis of recently proposed arithmetic components. We find that careful initialization, restricting parameter space, and regularizing for sparsity is important when optimizing the NAU and NMU. Our proposed units NAU and NMU, compared with previous neural units, converge more consistently, have fewer parameters, learn faster, can converge for larger hidden sizes, obtain sparse and meaningful weights, and can extrapolate to negative and small values.
      o *Code:* https://github.com/AndreasMadsen/stable-nalu
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1gNOeHKPS&name=original_pdf>
  *


            DeepSphere: a graph-based spherical CNN
            <https://openreview.net/forum?id=B1e3OlStPB>
            <https://openreview.net/pdf?id=B1e3OlStPB>

    Michaël Defferrard
    <https://openreview.net/profile?email=michael.defferrard%40epfl.ch>,
    Martino Milani
    <https://openreview.net/profile?email=martino.milani%40epfl.ch>,
    Frédérick Gusset
    <https://openreview.net/profile?email=frederick.gusset%40epfl.ch>,
    Nathanaël Perraudin
    <https://openreview.net/profile?email=nathanael.perraudin%40sdsc.ethz.ch>

    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#B1e3OlStPB-details-171>
      o *TL;DR:* A graph-based spherical CNN that strikes an interesting balance of trade-offs for a wide variety of applications.
      o *Abstract:* Designing a convolution for a spherical neural network requires a delicate tradeoff between efficiency and rotation equivariance. DeepSphere, a method based on a graph representation of the discretized sphere, strikes a controllable balance between these two desiderata. This contribution is twofold. First, we study both theoretically and empirically how equivariance is affected by the underlying graph with respect to the number of pixels and neighbors. Second, we evaluate DeepSphere on relevant problems. Experiments show state-of-the-art performance and demonstrates the efficiency and flexibility of this formulation. Perhaps surprisingly, comparison with previous work suggests that anisotropic filters might be an unnecessary price to pay. Our code is available at https://github.com/deepsphere.
      o *Keywords:* spherical cnns, graph neural networks, geometric deep learning
      o *Code:* https://github.com/deepsphere
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=B1e3OlStPB&name=original_pdf>
  *


            SUMO: Unbiased Estimation of Log Marginal Probability for
            Latent Variable Models
            <https://openreview.net/forum?id=SylkYeHtwr>
            <https://openreview.net/pdf?id=SylkYeHtwr>

    Yucen Luo
    <https://openreview.net/profile?email=luoyc15%40mails.tsinghua.edu.cn>,
    Alex Beatson
    <https://openreview.net/profile?email=abeatson%40cs.princeton.edu>,
    Mohammad Norouzi
    <https://openreview.net/profile?email=mnorouzi%40google.com>, Jun
    Zhu
    <https://openreview.net/profile?email=dcszj%40mail.tsinghua.edu.cn>,
    David Duvenaud
    <https://openreview.net/profile?email=duvenaud%40cs.toronto.edu>,
    Ryan P. Adams
    <https://openreview.net/profile?email=rpa%40princeton.edu>, Ricky T.
    Q. Chen
    <https://openreview.net/profile?email=rtqichen%40cs.toronto.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#SylkYeHtwr-details-142>
      o *TL;DR:* We create an unbiased estimator for the log probability of latent variable models, extending such models to a larger scope of applications.
      o *Abstract:* Standard variational lower bounds used to train latent variable models produce biased estimates of most quantities of interest. We introduce an unbiased estimator of the log marginal likelihood and its gradients for latent variable models based on randomized truncation of infinite series. If parameterized by an encoder-decoder architecture, the parameters of the encoder can be optimized to minimize its variance of this estimator. We show that models trained using our estimator give better test-set likelihoods than a standard importance-sampling based approach for the same average computational cost. This estimator also allows use of latent variable models for tasks where unbiased estimators, rather than marginal likelihood lower bounds, are preferred, such as minimizing reverse KL divergences and estimating score functions.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SylkYeHtwr&name=original_pdf>
  *


            Deep Learning For Symbolic Mathematics
            <https://openreview.net/forum?id=S1eZYeHFDS>
            <https://openreview.net/pdf?id=S1eZYeHFDS>

    Guillaume Lample
    <https://openreview.net/profile?email=guillaume.lample%40gmail.com>,
    François Charton
    <https://openreview.net/profile?email=fcharton%40fb.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 30 Replies
    Show details <#S1eZYeHFDS-details-136>
      o *TL;DR:* We train a neural network to compute function integrals, and to solve complex differential equations.
      o *Abstract:* Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing these mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.
      o *Keywords:* symbolic, math, deep learning, transformers
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1eZYeHFDS&name=original_pdf>
  *


            Making Sense of Reinforcement Learning and Probabilistic
            Inference <https://openreview.net/forum?id=S1xitgHtvS>
            <https://openreview.net/pdf?id=S1xitgHtvS>

    Brendan O'Donoghue
    <https://openreview.net/profile?email=bodonoghue85%40gmail.com>, Ian
    Osband <https://openreview.net/profile?email=iosband%40google.com>,
    Catalin Ionescu <https://openreview.net/profile?email=cdi%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 11 Replies
    Show details <#S1xitgHtvS-details-517>
      o *TL;DR:* Popular algorithms that cast "RL as Inference" ignore the role of uncertainty and exploration. We highlight the importance of these issues and present a coherent framework for RL and inference that handles them gracefully.
      o *Abstract:* Reinforcement learning (RL) combines a control problem with statistical estimation: The system dynamics are not known to the agent, but can be learned through experience. A recent line of research casts ‘RL as inference’ and suggests a particular framework to generalize the RL problem as probabilistic inference. Our paper surfaces a key shortcoming in that approach, and clarifies the sense in which RL can be coherently cast as an inference problem. In particular, an RL agent must consider the effects of its actions upon future rewards and observations: The exploration-exploitation tradeoff. In all but the most simple settings, the resulting inference is computationally intractable so that practical RL algorithms must resort to approximation. We demonstrate that the popular ‘RL as inference’ approximation can perform poorly in even very basic problems. However, we show that with a small modification the framework does yield algorithms that can provably perform well, and we show that the resulting algorithm is equivalent to the recently proposed K-learning, which we further connect with Thompson sampling.
              
      o *Keywords:* Reinforcement learning, Bayesian inference, Exploration
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1xitgHtvS&name=original_pdf>
  *


            Unbiased Contrastive Divergence Algorithm for Training
            Energy-Based Latent Variable Models
            <https://openreview.net/forum?id=r1eyceSYPr>
            <https://openreview.net/pdf?id=r1eyceSYPr>

    Yixuan Qiu
    <https://openreview.net/profile?email=yixuanq%40andrew.cmu.edu>,
    Lingsong Zhang
    <https://openreview.net/profile?email=lingsong%40purdue.edu>, Xiao
    Wang <https://openreview.net/profile?email=wangxiao%40purdue.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 13 Replies
    Show details <#r1eyceSYPr-details-566>
      o *TL;DR:* We have developed a new training algorithm for energy-based latent variable models that completely removes the bias of contrastive divergence.
      o *Abstract:* The contrastive divergence algorithm is a popular approach to training energy-based latent variable models, which has been widely used in many machine learning models such as the restricted Boltzmann machines and deep belief nets. Despite its empirical success, the contrastive divergence algorithm is also known to have biases that severely affect its convergence. In this article we propose an unbiased version of the contrastive divergence algorithm that completely removes its bias in stochastic gradient methods, based on recent advances on unbiased Markov chain Monte Carlo methods. Rigorous theoretical analysis is developed to justify the proposed algorithm, and numerical experiments show that it significantly improves the existing method. Our findings suggest that the unbiased contrastive divergence algorithm is a promising approach to training general energy-based latent variable models.
      o *Keywords:* energy model, restricted Boltzmann machine, contrastive divergence, unbiased Markov chain Monte Carlo, distribution coupling
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=r1eyceSYPr&name=original_pdf>
  *


            A Mutual Information Maximization Perspective of Language
            Representation Learning
            <https://openreview.net/forum?id=Syx79eBKwr>
            <https://openreview.net/pdf?id=Syx79eBKwr>

    Lingpeng Kong
    <https://openreview.net/profile?email=lingpenk%40google.com>,
    Cyprien de Masson d'Autume
    <https://openreview.net/profile?email=cyprien%40google.com>, Lei Yu
    <https://openreview.net/profile?email=leiyu%40google.com>, Wang Ling
    <https://openreview.net/profile?email=lingwang%40google.com>, Zihang
    Dai <https://openreview.net/profile?email=zihangd%40google.com>,
    Dani Yogatama
    <https://openreview.net/profile?email=dyogatama%40google.com>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 12 Replies
    Show details <#Syx79eBKwr-details-618>
      o *Abstract:* We show state-of-the-art word representation learning methods maximize an objective function that is a lower bound on the mutual information between different parts of a word sequence (i.e., a sentence). Our formulation provides an alternative perspective that unifies classical word embedding models (e.g., Skip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to enhancing our theoretical understanding of these methods, our derivation leads to a principled framework that can be used to construct new self-supervised tasks. We provide an example by drawing inspirations from related methods based on mutual information maximization that have been successful in computer vision, and introduce a simple self-supervised objective that maximizes the mutual information between a global sentence representation and n-grams in the sentence. Our analysis offers a holistic view of representation learning methods to transfer knowledge and translate progress across multiple domains (e.g., natural language processing, computer vision, audio processing).
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=Syx79eBKwr&name=original_pdf>
  *


            Energy-based models for atomic-resolution protein
            conformations <https://openreview.net/forum?id=S1e_9xrFvS>
            <https://openreview.net/pdf?id=S1e_9xrFvS>

    Yilun Du <https://openreview.net/profile?email=yilundu%40mit.edu>,
    Joshua Meier <https://openreview.net/profile?email=jmeier%40fb.com>,
    Jerry Ma <https://openreview.net/profile?email=maj%40fb.com>, Rob
    Fergus <https://openreview.net/profile?email=robfergus%40fb.com>,
    Alexander Rives
    <https://openreview.net/profile?email=arives%40cs.nyu.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#S1e_9xrFvS-details-885>
      o *TL;DR:* Energy-based models trained on crystallized protein structures predict native side chain configurations and automatically discover molecular energy features.
      o *Abstract:* We propose an energy-based model (EBM) of protein conformations that operates at atomic scale. The model is trained solely on crystallized protein data. By contrast, existing approaches for scoring conformations use energy functions that incorporate knowledge of physical principles and features that are the complex product of several decades of research and tuning. To evaluate the model, we benchmark on the rotamer recovery task, the problem of predicting the conformation of a side chain from its context within a protein structure, which has been used to evaluate energy functions for protein design. The model achieves performance close to that of the Rosetta energy function, a state-of-the-art method widely used in protein structure prediction and design. An investigation of the model’s outputs and hidden representations finds that it captures physicochemical properties relevant to protein energy.
      o *Keywords:* energy-based model, transformer, energy function, protein conformation
      o *Code:* https://github.com/facebookresearch/protein-ebm
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1e_9xrFvS&name=original_pdf>
  *


            Depth-Width Trade-offs for ReLU Networks via Sharkovsky's
            Theorem <https://openreview.net/forum?id=BJe55gBtvH>
            <https://openreview.net/pdf?id=BJe55gBtvH>

    Vaggos Chatziafratis
    <https://openreview.net/profile?email=vaggos%40cs.stanford.edu>, Sai
    Ganesh Nagarajan
    <https://openreview.net/profile?email=sai_nagarajan%40mymail.sutd.edu.sg>,
    Ioannis Panageas
    <https://openreview.net/profile?email=ioannis%40sutd.edu.sg>, Xiao
    Wang <https://openreview.net/profile?email=xiao_wang%40sutd.edu.sg>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 6 Replies
    Show details <#BJe55gBtvH-details-411>
      o *TL;DR:* In this work, we point to a new connection between DNNs expressivity and Sharkovsky’s Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks 
      o *Abstract:* Understanding the representational power of Deep Neural Networks (DNNs) and how their structural properties (e.g., depth, width, type of activation unit) affect the functions they can compute, has been an important yet challenging question in deep learning and approximation theory. In a seminal paper, Telgarsky high- lighted the benefits of depth by presenting a family of functions (based on sim- ple triangular waves) for which DNNs achieve zero classification error, whereas shallow networks with fewer than exponentially many nodes incur constant error. Even though Telgarsky’s work reveals the limitations of shallow neural networks, it doesn’t inform us on why these functions are difficult to represent and in fact he states it as a tantalizing open question to characterize those functions that cannot be well-approximated by smaller depths.
              In this work, we point to a new connection between DNNs expressivity and Sharkovsky’s Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks for representing functions based on the presence of a generalized notion of fixed points, called periodic points (a fixed point is a point of period 1). Motivated by our observation that the triangle waves used in Telgarsky’s work contain points of period 3 – a period that is special in that it implies chaotic behaviour based on the celebrated result by Li-Yorke – we proceed to give general lower bounds for the width needed to represent periodic functions as a function of the depth. Technically, the crux of our approach is based on an eigenvalue analysis of the dynamical systems associated with such functions.
      o *Code:* https://docs.google.com/document/d/1qr-sROZ7q93OhigF6CoPde5NQ901wI17wmnBvbZRT9s/edit?fbclid=IwAR1HwkNZ1g2QgMmTGRZ0ktCYNgeKKk91tvRNLb59QJwU3dRmuGCJbTNMwj0
      o *Keywords:* Depth-Width trade-offs, ReLU networks, chaos theory, Sharkovsky Theorem, dynamical systems
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=BJe55gBtvH&name=original_pdf>
  *


            Generalization of Two-layer Neural Networks: An Asymptotic
            Viewpoint <https://openreview.net/forum?id=H1gBsgBYwH>
            <https://openreview.net/pdf?id=H1gBsgBYwH>

    Jimmy Ba
    <https://openreview.net/profile?email=jba%40cs.toronto.edu>, Murat
    Erdogdu
    <https://openreview.net/profile?email=erdogdu%40cs.toronto.edu>,
    Taiji Suzuki
    <https://openreview.net/profile?email=taiji%40mist.i.u-tokyo.ac.jp>,
    Denny Wu
    <https://openreview.net/profile?email=dennywu%40cs.toronto.edu>,
    Tianzong Zhang
    <https://openreview.net/profile?email=ztz16%40mails.tsinghua.edu.cn>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 7 Replies
    Show details <#H1gBsgBYwH-details-642>
      o *TL;DR:* Derived population risk of two-layer neural networks in high dimensions and examined presence / absence of  "double descent".
      o *Abstract:* This paper investigates the generalization properties of two-layer neural networks in high-dimensions, i.e. when the number of samples $n$, features $d$, and neurons $h$ tend to infinity at the same rate. Specifically, we derive the exact population risk of the unregularized least squares regression problem with two-layer neural networks when either the first or the second layer is trained using a gradient flow under different initialization setups.  When only the second layer coefficients are optimized, we recover the \textit{double descent} phenomenon: a cusp in the population risk appears at $h\approx n$ and further overparameterization decreases the risk. In contrast, when the first layer weights are optimized, we highlight how different scales of initialization lead to different inductive bias, and show that the resulting risk is \textit{independent} of overparameterization. Our theoretical and experimental results suggest that previously studied model setups that provably give rise to \textit{double descent} might not translate to optimizing two-layer neural networks.
      o *Keywords:* Neural Networks, Generalization, High-dimensional Statistics
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=H1gBsgBYwH&name=original_pdf>
  *


            Reconstructing continuous distributions of 3D protein
            structure from cryo-EM images
            <https://openreview.net/forum?id=SJxUjlBtwB>
            <https://openreview.net/pdf?id=SJxUjlBtwB>

    Ellen D. Zhong
    <https://openreview.net/profile?email=zhonge%40mit.edu>, Tristan
    Bepler <https://openreview.net/profile?email=tbepler%40mit.edu>,
    Joseph H. Davis
    <https://openreview.net/profile?email=jhdavis%40mit.edu>, Bonnie
    Berger <https://openreview.net/profile?email=bab%40mit.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 9 Replies
    Show details <#SJxUjlBtwB-details-333>
      o *TL;DR:* We propose a deep generative model of volumes for 3D cryo-EM reconstruction from unlabelled 2D images and show that it can learn can learn continuous deformations in protein structure.
      o *Abstract:* Cryo-electron microscopy (cryo-EM) is a powerful technique for determining the structure of proteins and other macromolecular complexes at near-atomic resolution. In single particle cryo-EM, the central problem is to reconstruct the 3D structure of a macromolecule from $10^{4-7}$ noisy and randomly oriented 2D projection images. However, the imaged protein complexes may exhibit structural variability, which complicates reconstruction and is typically addressed using discrete clustering approaches that fail to capture the full range of protein dynamics. Here, we introduce a novel method for cryo-EM reconstruction that extends naturally to modeling continuous generative factors of structural heterogeneity. This method encodes structures in Fourier space using coordinate-based deep neural networks, and trains these networks from unlabeled 2D cryo-EM images by combining exact inference over image orientation with variational inference for structural heterogeneity. We demonstrate that the proposed method, termed cryoDRGN, can perform ab-initio reconstruction of 3D protein complexes from simulated and real 2D cryo-EM image data. To our knowledge, cryoDRGN is the first neural network-based approach for cryo-EM reconstruction and the first end-to-end method for directly reconstructing continuous ensembles of protein structures from cryo-EM images.
      o *Keywords:* generative models, proteins, 3D reconstruction, cryo-EM
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SJxUjlBtwB&name=original_pdf>
  *


            PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL
            REPRESENTATIONS <https://openreview.net/forum?id=SJxpsxrYPS>
            <https://openreview.net/pdf?id=SJxpsxrYPS>

    Zhiyuan Li <https://openreview.net/profile?email=zl7904%40rit.edu>,
    Jaideep Vitthal Murkute
    <https://openreview.net/profile?email=jvm6526%40rit.edu>, Prashnna
    Kumar Gyawali
    <https://openreview.net/profile?email=pkg2182%40rit.edu>, Linwei
    Wang <https://openreview.net/profile?email=linwei.wang%40rit.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#SJxpsxrYPS-details-579>
      o *TL;DR:* We proposed a progressive learning method to improve learning and disentangling latent representations at different levels of abstraction.
      o *Abstract:* Learning rich representation from data is an important task for deep generative models such as variational auto-encoder (VAE). However, by extracting high-level abstractions in the bottom-up inference process, the goal of preserving all factors of variations for top-down generation is compromised. Motivated by the concept of “starting small”, we present a strategy to progressively learn independent hierarchical representations from high- to low-levels of abstractions. The model starts with learning the most abstract representation, and then progressively grow the network architecture to introduce new  representations at different levels of abstraction. We quantitatively demonstrate the ability of the presented model to improve disentanglement in comparison to existing works on two benchmark datasets using three disentanglement metrics, including a new metric we proposed to complement the previously-presented metric of mutual information gap. We further present both qualitative and quantitative evidence on how the progression of learning improves disentangling of hierarchical representations. By drawing on the respective advantage of hierarchical representation learning and progressive learning, this is to our knowledge the first attempt to improve disentanglement by progressively growing the capacity of VAE to learn hierarchical representations.
      o *Keywords:* generative model, disentanglement, progressive learning, VAE
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=SJxpsxrYPS&name=original_pdf>
  *


            An Exponential Learning Rate Schedule for Deep Learning
            <https://openreview.net/forum?id=rJg8TeSFDH>
            <https://openreview.net/pdf?id=rJg8TeSFDH>

    Zhiyuan Li
    <https://openreview.net/profile?email=zhiyuanli%40cs.princeton.edu>,
    Sanjeev Arora
    <https://openreview.net/profile?email=arora%40cs.princeton.edu>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 10 Replies
    Show details <#rJg8TeSFDH-details-79>
      o *TL;DR:* We propose an exponentially growing learning rate schedule for networks with BatchNorm, which surprisingly performs well in practice and is provably equivalent to popular LR schedules like Step Decay.
      o *Abstract:* Intriguing empirical evidence exists that deep learning can work well with exotic schedules for varying the learning rate. This paper suggests that the phenomenon may be due to Batch Normalization or BN(Ioffe & Szegedy, 2015), which is ubiq- uitous and provides benefits in optimization and generalization across all standard architectures. The following new results are shown about BN with weight decay and momentum (in other words, the typical use case which was not considered in earlier theoretical analyses of stand-alone BN (Ioffe & Szegedy, 2015; Santurkar et al., 2018; Arora et al., 2018)
              • Training can be done using SGD with momentum and an exponentially in- creasing learning rate schedule, i.e., learning rate increases by some (1 + α) factor in every epoch for some α > 0. (Precise statement in the paper.) To the best of our knowledge this is the first time such a rate schedule has been successfully used, let alone for highly successful architectures. As ex- pected, such training rapidly blows up network weights, but the net stays well-behaved due to normalization.
              • Mathematical explanation of the success of the above rate schedule: a rigor- ous proof that it is equivalent to the standard setting of BN + SGD + Standard Rate Tuning + Weight Decay + Momentum. This equivalence holds for other normalization layers as well, Group Normalization(Wu & He, 2018), Layer Normalization(Ba et al., 2016), Instance Norm(Ulyanov et al., 2016), etc.
              • A worked-out toy example illustrating the above linkage of hyper- parameters. Using either weight decay or BN alone reaches global minimum, but convergence fails when both are used.
      o *Keywords:* batch normalization, weight decay, learning rate, deep learning theory
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=rJg8TeSFDH&name=original_pdf>
  *


            Geom-GCN: Geometric Graph Convolutional Networks
            <https://openreview.net/forum?id=S1e2agrFvS>
            <https://openreview.net/pdf?id=S1e2agrFvS>

    Hongbin Pei
    <https://openreview.net/profile?email=gspeihongbing%40163.com>,
    Bingzhe Wei
    <https://openreview.net/profile?email=bwei6%40illinois.edu>, Kevin
    Chen-Chuan Chang
    <https://openreview.net/profile?email=kcchang%40illinois.edu>, Yu
    Lei
    <https://openreview.net/profile?email=csylei%40comp.polyu.edu.hk>,
    Bo Yang <https://openreview.net/profile?email=ybo%40jlu.edu.cn>
    25 Sep 2019 (modified: 11 Mar 2020) ICLR 2020 Conference Blind
    Submission Readers: Everyone 19 Replies
    Show details <#S1e2agrFvS-details-756>
      o *Abstract:* Message-passing neural networks (MPNNs) have been successfully applied in a wide variety of applications in the real world. However, two fundamental weaknesses of MPNNs' aggregators limit their ability to represent graph-structured data: losing the structural information of nodes in neighborhoods and lacking the ability to capture long-range dependencies in disassortative graphs. Few studies have noticed the weaknesses from different perspectives. From the observations on classical neural network and network geometry, we propose a novel geometric aggregation scheme for graph neural networks to overcome the two weaknesses.  The behind basic idea is the aggregation on a graph can benefit from a continuous space underlying the graph. The proposed aggregation scheme is permutation-invariant and consists of three modules, node embedding, structural neighborhood, and bi-level aggregation. We also present an implementation of the scheme in graph convolutional networks, termed Geom-GCN, to perform transductive learning on graphs. Experimental results show the proposed Geom-GCN achieved state-of-the-art performance on a wide range of open datasets of graphs.
      o *Keywords:* Deep Learning, Graph Convolutional Network, Network Geometry
      o *Code:* https://github.com/graphdml-uiuc-jlu/geom-gcn
      o *TL;DR:* For graph neural networks, the aggregation on a graph can benefit from a continuous space underlying the graph.
      o *Original Pdf:*   pdf <https://openreview.net/attachment?id=S1e2agrFvS&name=original_pdf>

Loading

  * About OpenReview <https://openreview.net/about>
  * Hosting a Venue <https://openreview.net/group?id=OpenReview.net/Support>
  * All Venues <https://openreview.net/venues>

  * Contact <https://openreview.net/contact>
  * Feedback <#>
  * *Join the Team*
    <https://codeforscience.org/jobs?job=OpenReview-Developer>

  * Frequently Asked Questions <https://openreview.net/faq>
  * Terms of Service <https://openreview.net/terms>
  * Privacy Policy <https://openreview.net/privacy>

  * About OpenReview <https://openreview.net/about>
  * Hosting a Venue <https://openreview.net/group?id=OpenReview.net/Support>
  * All Venues <https://openreview.net/venues>
  * *Join the Team*
    <https://codeforscience.org/jobs?job=OpenReview-Developer>

  * FAQ <https://openreview.net/faq>
  * Contact <https://openreview.net/contact>
  * Feedback <#>
  * Terms of Service <https://openreview.net/terms>
  * Privacy Policy <https://openreview.net/privacy>

OpenReview is created by the Information Extraction and Synthesis
Laboratory <http://www.iesl.cs.umass.edu/>, College of Information and
Computer Science, University of Massachusetts Amherst. We gratefully
acknowledge the support of the OpenReview sponsors: Google, Facebook,
NSF, the University of Massachusetts Amherst Center for Data Science,
and Center for Intelligent Information Retrieval, as well as the Google
Cloud Platform for donating the computing and networking services on
which OpenReview.net runs.

×


      Send Feedback

Enter your feedback below and we'll get back to you as soon as possible.

Cancel Send
